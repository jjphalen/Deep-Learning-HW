{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Fear and Greed Index\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin fear and greed index values to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value\n",
       "date                  \n",
       "2019-07-29          19\n",
       "2019-07-28          16\n",
       "2019-07-27          47\n",
       "2019-07-26          24\n",
       "2019-07-25          42"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2019-07-25    9882.429688\n",
       "2019-07-26    9847.450195\n",
       "2019-07-27    9478.320313\n",
       "2019-07-28    9531.769531\n",
       "2019-07-29    9529.889648\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the historical closing prices for Bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "      <td>9882.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "      <td>9847.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "      <td>9478.320313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "      <td>9531.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "      <td>9529.889648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2019-07-25          42  9882.429688\n",
       "2019-07-26          24  9847.450195\n",
       "2019-07-27          47  9478.320313\n",
       "2019-07-28          16  9531.769531\n",
       "2019-07-29          19  9529.889648"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>30</td>\n",
       "      <td>9114.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>15</td>\n",
       "      <td>8870.820313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-03</th>\n",
       "      <td>40</td>\n",
       "      <td>9251.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8218.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>11</td>\n",
       "      <td>6937.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2018-02-01          30  9114.719727\n",
       "2018-02-02          15  8870.820313\n",
       "2018-02-03          40  9251.269531\n",
       "2018-02-04          24  8218.049805\n",
       "2018-02-05          11  6937.080078"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of fear and greed index values and a target of the 11th day closing price\n",
    "# Try a window size anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 1\n",
    "\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 0\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30],\n",
       "       [15],\n",
       "       [40],\n",
       "       [24],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [36],\n",
       "       [30],\n",
       "       [44],\n",
       "       [54],\n",
       "       [31],\n",
       "       [42],\n",
       "       [35],\n",
       "       [55],\n",
       "       [71],\n",
       "       [67],\n",
       "       [74],\n",
       "       [63],\n",
       "       [67],\n",
       "       [74],\n",
       "       [54],\n",
       "       [44],\n",
       "       [39],\n",
       "       [31],\n",
       "       [33],\n",
       "       [37],\n",
       "       [44],\n",
       "       [41],\n",
       "       [38],\n",
       "       [47],\n",
       "       [56],\n",
       "       [44],\n",
       "       [55],\n",
       "       [59],\n",
       "       [37],\n",
       "       [39],\n",
       "       [37],\n",
       "       [39],\n",
       "       [40],\n",
       "       [41],\n",
       "       [41],\n",
       "       [40],\n",
       "       [32],\n",
       "       [33],\n",
       "       [31],\n",
       "       [29],\n",
       "       [29],\n",
       "       [37],\n",
       "       [36],\n",
       "       [36],\n",
       "       [28],\n",
       "       [32],\n",
       "       [30],\n",
       "       [31],\n",
       "       [24],\n",
       "       [24],\n",
       "       [18],\n",
       "       [12],\n",
       "       [16],\n",
       "       [16],\n",
       "       [11],\n",
       "       [22],\n",
       "       [22],\n",
       "       [17],\n",
       "       [19],\n",
       "       [20],\n",
       "       [17],\n",
       "       [21],\n",
       "       [18],\n",
       "       [20],\n",
       "       [18],\n",
       "       [23],\n",
       "       [26],\n",
       "       [24],\n",
       "       [25],\n",
       "       [26],\n",
       "       [32],\n",
       "       [31],\n",
       "       [28],\n",
       "       [29],\n",
       "       [64],\n",
       "       [47],\n",
       "       [55],\n",
       "       [54],\n",
       "       [61],\n",
       "       [59],\n",
       "       [56],\n",
       "       [52],\n",
       "       [55],\n",
       "       [56],\n",
       "       [63],\n",
       "       [67],\n",
       "       [56],\n",
       "       [62],\n",
       "       [53],\n",
       "       [63],\n",
       "       [41],\n",
       "       [44],\n",
       "       [40],\n",
       "       [40],\n",
       "       [40],\n",
       "       [32],\n",
       "       [31],\n",
       "       [37],\n",
       "       [31],\n",
       "       [32],\n",
       "       [41],\n",
       "       [30],\n",
       "       [26],\n",
       "       [27],\n",
       "       [25],\n",
       "       [23],\n",
       "       [19],\n",
       "       [22],\n",
       "       [16],\n",
       "       [38],\n",
       "       [25],\n",
       "       [24],\n",
       "       [27],\n",
       "       [40],\n",
       "       [41],\n",
       "       [26],\n",
       "       [42],\n",
       "       [38],\n",
       "       [40],\n",
       "       [39],\n",
       "       [24],\n",
       "       [15],\n",
       "       [19],\n",
       "       [19],\n",
       "       [17],\n",
       "       [26],\n",
       "       [22],\n",
       "       [23],\n",
       "       [27],\n",
       "       [32],\n",
       "       [34],\n",
       "       [37],\n",
       "       [28],\n",
       "       [17],\n",
       "       [15],\n",
       "       [16],\n",
       "       [21],\n",
       "       [18],\n",
       "       [20],\n",
       "       [16],\n",
       "       [22],\n",
       "       [27],\n",
       "       [27],\n",
       "       [31],\n",
       "       [33],\n",
       "       [37],\n",
       "       [34],\n",
       "       [34],\n",
       "       [38],\n",
       "       [39],\n",
       "       [37],\n",
       "       [29],\n",
       "       [33],\n",
       "       [29],\n",
       "       [29],\n",
       "       [32],\n",
       "       [36],\n",
       "       [39],\n",
       "       [42],\n",
       "       [44],\n",
       "       [47],\n",
       "       [43],\n",
       "       [46],\n",
       "       [44],\n",
       "       [49],\n",
       "       [54],\n",
       "       [53],\n",
       "       [47],\n",
       "       [54],\n",
       "       [54],\n",
       "       [53],\n",
       "       [48],\n",
       "       [39],\n",
       "       [39],\n",
       "       [36],\n",
       "       [31],\n",
       "       [23],\n",
       "       [25],\n",
       "       [25],\n",
       "       [23],\n",
       "       [19],\n",
       "       [21],\n",
       "       [18],\n",
       "       [18],\n",
       "       [21],\n",
       "       [16],\n",
       "       [18],\n",
       "       [21],\n",
       "       [19],\n",
       "       [24],\n",
       "       [27],\n",
       "       [26],\n",
       "       [19],\n",
       "       [21],\n",
       "       [18],\n",
       "       [19],\n",
       "       [22],\n",
       "       [19],\n",
       "       [18],\n",
       "       [19],\n",
       "       [19],\n",
       "       [22],\n",
       "       [17],\n",
       "       [21],\n",
       "       [18],\n",
       "       [19],\n",
       "       [26],\n",
       "       [17],\n",
       "       [14],\n",
       "       [17],\n",
       "       [18],\n",
       "       [13],\n",
       "       [15],\n",
       "       [18],\n",
       "       [14],\n",
       "       [20],\n",
       "       [23],\n",
       "       [24],\n",
       "       [28],\n",
       "       [25],\n",
       "       [21],\n",
       "       [24],\n",
       "       [24],\n",
       "       [31],\n",
       "       [35],\n",
       "       [38],\n",
       "       [43],\n",
       "       [37],\n",
       "       [37],\n",
       "       [42],\n",
       "       [42],\n",
       "       [37],\n",
       "       [34],\n",
       "       [35],\n",
       "       [33],\n",
       "       [36],\n",
       "       [29],\n",
       "       [37],\n",
       "       [34],\n",
       "       [29],\n",
       "       [26],\n",
       "       [31],\n",
       "       [28],\n",
       "       [19],\n",
       "       [13],\n",
       "       [15],\n",
       "       [18],\n",
       "       [20],\n",
       "       [24],\n",
       "       [23],\n",
       "       [26],\n",
       "       [24],\n",
       "       [21],\n",
       "       [21],\n",
       "       [27],\n",
       "       [24],\n",
       "       [23],\n",
       "       [25],\n",
       "       [29],\n",
       "       [33],\n",
       "       [35],\n",
       "       [34],\n",
       "       [31],\n",
       "       [32],\n",
       "       [29],\n",
       "       [36],\n",
       "       [36],\n",
       "       [41],\n",
       "       [42],\n",
       "       [42],\n",
       "       [48],\n",
       "       [51],\n",
       "       [47],\n",
       "       [52],\n",
       "       [54],\n",
       "       [52],\n",
       "       [56],\n",
       "       [49],\n",
       "       [28],\n",
       "       [23],\n",
       "       [24],\n",
       "       [26],\n",
       "       [28],\n",
       "       [21],\n",
       "       [15],\n",
       "       [14],\n",
       "       [12],\n",
       "       [15],\n",
       "       [ 9],\n",
       "       [17],\n",
       "       [11],\n",
       "       [14],\n",
       "       [18],\n",
       "       [19],\n",
       "       [13],\n",
       "       [15],\n",
       "       [17],\n",
       "       [12],\n",
       "       [19],\n",
       "       [13],\n",
       "       [11],\n",
       "       [11],\n",
       "       [14],\n",
       "       [19],\n",
       "       [15],\n",
       "       [14],\n",
       "       [14],\n",
       "       [10],\n",
       "       [11],\n",
       "       [13],\n",
       "       [17],\n",
       "       [23],\n",
       "       [21],\n",
       "       [27],\n",
       "       [35],\n",
       "       [28],\n",
       "       [31],\n",
       "       [25],\n",
       "       [33],\n",
       "       [26],\n",
       "       [29],\n",
       "       [21],\n",
       "       [24],\n",
       "       [23],\n",
       "       [26],\n",
       "       [24],\n",
       "       [30],\n",
       "       [33],\n",
       "       [48],\n",
       "       [36],\n",
       "       [31],\n",
       "       [39],\n",
       "       [39],\n",
       "       [42],\n",
       "       [37],\n",
       "       [19],\n",
       "       [22],\n",
       "       [21],\n",
       "       [16],\n",
       "       [27],\n",
       "       [24],\n",
       "       [28],\n",
       "       [29],\n",
       "       [31],\n",
       "       [35],\n",
       "       [30],\n",
       "       [27],\n",
       "       [33],\n",
       "       [37],\n",
       "       [35],\n",
       "       [41],\n",
       "       [39],\n",
       "       [35],\n",
       "       [21],\n",
       "       [15],\n",
       "       [22],\n",
       "       [17],\n",
       "       [23],\n",
       "       [22],\n",
       "       [19],\n",
       "       [27],\n",
       "       [21],\n",
       "       [14],\n",
       "       [18],\n",
       "       [37],\n",
       "       [42],\n",
       "       [40],\n",
       "       [46],\n",
       "       [38],\n",
       "       [48],\n",
       "       [48],\n",
       "       [43],\n",
       "       [43],\n",
       "       [41],\n",
       "       [38],\n",
       "       [63],\n",
       "       [65],\n",
       "       [59],\n",
       "       [59],\n",
       "       [61],\n",
       "       [63],\n",
       "       [69],\n",
       "       [47],\n",
       "       [40],\n",
       "       [39],\n",
       "       [39],\n",
       "       [42],\n",
       "       [41],\n",
       "       [44],\n",
       "       [36],\n",
       "       [35],\n",
       "       [42],\n",
       "       [56],\n",
       "       [54],\n",
       "       [55],\n",
       "       [55],\n",
       "       [56],\n",
       "       [56],\n",
       "       [54],\n",
       "       [55],\n",
       "       [55],\n",
       "       [54],\n",
       "       [58],\n",
       "       [56],\n",
       "       [56],\n",
       "       [55],\n",
       "       [62],\n",
       "       [56],\n",
       "       [50],\n",
       "       [44],\n",
       "       [46],\n",
       "       [43],\n",
       "       [44],\n",
       "       [49],\n",
       "       [50],\n",
       "       [57],\n",
       "       [56],\n",
       "       [62],\n",
       "       [60],\n",
       "       [71],\n",
       "       [61],\n",
       "       [59],\n",
       "       [65],\n",
       "       [69],\n",
       "       [65],\n",
       "       [64],\n",
       "       [62],\n",
       "       [65],\n",
       "       [42],\n",
       "       [62],\n",
       "       [51],\n",
       "       [60],\n",
       "       [50],\n",
       "       [61],\n",
       "       [64],\n",
       "       [61],\n",
       "       [62],\n",
       "       [62],\n",
       "       [61],\n",
       "       [68],\n",
       "       [65],\n",
       "       [58],\n",
       "       [41],\n",
       "       [42],\n",
       "       [40],\n",
       "       [42],\n",
       "       [42],\n",
       "       [51],\n",
       "       [50],\n",
       "       [63],\n",
       "       [66],\n",
       "       [67],\n",
       "       [57],\n",
       "       [69],\n",
       "       [63],\n",
       "       [69],\n",
       "       [71],\n",
       "       [76],\n",
       "       [75],\n",
       "       [78],\n",
       "       [78],\n",
       "       [77],\n",
       "       [75],\n",
       "       [65],\n",
       "       [67],\n",
       "       [70],\n",
       "       [73],\n",
       "       [68],\n",
       "       [69],\n",
       "       [65],\n",
       "       [64],\n",
       "       [69],\n",
       "       [67],\n",
       "       [70],\n",
       "       [71],\n",
       "       [71],\n",
       "       [73],\n",
       "       [61],\n",
       "       [62],\n",
       "       [63],\n",
       "       [66],\n",
       "       [42],\n",
       "       [27],\n",
       "       [34],\n",
       "       [27],\n",
       "       [62],\n",
       "       [62],\n",
       "       [46],\n",
       "       [61],\n",
       "       [60],\n",
       "       [63],\n",
       "       [67],\n",
       "       [75],\n",
       "       [80],\n",
       "       [84],\n",
       "       [83],\n",
       "       [82],\n",
       "       [81],\n",
       "       [84],\n",
       "       [83],\n",
       "       [84],\n",
       "       [80],\n",
       "       [87],\n",
       "       [95],\n",
       "       [92],\n",
       "       [62],\n",
       "       [74],\n",
       "       [78],\n",
       "       [65],\n",
       "       [63],\n",
       "       [79],\n",
       "       [76],\n",
       "       [67],\n",
       "       [72],\n",
       "       [67],\n",
       "       [74],\n",
       "       [84],\n",
       "       [83],\n",
       "       [62],\n",
       "       [33],\n",
       "       [65],\n",
       "       [61],\n",
       "       [16],\n",
       "       [34],\n",
       "       [19],\n",
       "       [40],\n",
       "       [42],\n",
       "       [34],\n",
       "       [42],\n",
       "       [42],\n",
       "       [40],\n",
       "       [20],\n",
       "       [42],\n",
       "       [24],\n",
       "       [47]], dtype=int64)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n",
    "# YOUR CODE HERE!\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split = int(0.7 *len(X))\n",
    "X_train_rnn = X[: split -1]\n",
    "X_test = X[split:]\n",
    "y_train_rnn = y[: split -1]\n",
    "y_test = y[split:]\n",
    "\n",
    "X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MinMaxScaler to scale the data between 0 and 1. \n",
    "# YOUR CODE HERE!\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train_rnn =scaler.transform(X_train_rnn)\n",
    "X_val_rnn =scaler.transform(X_val_rnn)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "y_train_rnn = scaler.transform(y_train_rnn)\n",
    "y_val_rnn = scaler.transform(y_val_rnn)\n",
    "y_test =scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[0.33333333]]\n",
      "\n",
      " [[0.33333333]]\n",
      "\n",
      " [[0.20689655]]\n",
      "\n",
      " [[0.09195402]]\n",
      "\n",
      " [[0.31034483]]] \n",
      "\n",
      "X_val_rnn sample values:\n",
      "[[[0.22988506]]\n",
      "\n",
      " [[0.06896552]]\n",
      "\n",
      " [[0.63218391]]\n",
      "\n",
      " [[0.27586207]]\n",
      "\n",
      " [[0.26436782]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.40229885]]\n",
      "\n",
      " [[0.37931034]]\n",
      "\n",
      " [[0.34482759]]\n",
      "\n",
      " [[0.63218391]]\n",
      "\n",
      " [[0.65517241]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "# YOUR CODE HERE!\n",
    "X_train_rnn = X_train_rnn.reshape((X_train_rnn.shape[0], X_train_rnn.shape[1], 1))\n",
    "X_val_rnn = X_val_rnn.reshape((X_val_rnn.shape[0], X_val_rnn.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train_rnn[:5]} \\n\")\n",
    "print (f\"X_val_rnn sample values:\\n{X_val_rnn[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# YOUR CODE HERE!\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 30\n",
    "dropout_fraction = 0.5\n",
    "\n",
    "#first layer:\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train_rnn.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#second layer\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#third layer\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#fourth layer\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# YOUR CODE HERE!\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 1, 30)             3840      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 1, 30)             7320      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 1, 30)             7320      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 25,831\n",
      "Trainable params: 25,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "# YOUR CODE HERE!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 282 samples, validate on 95 samples\n",
      "Epoch 1/250\n",
      "282/282 [==============================] - 6s 22ms/sample - loss: 0.1621 - val_loss: 0.1458\n",
      "Epoch 2/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.1519 - val_loss: 0.1355\n",
      "Epoch 3/250\n",
      "282/282 [==============================] - 0s 165us/sample - loss: 0.1406 - val_loss: 0.1249\n",
      "Epoch 4/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.1300 - val_loss: 0.1136\n",
      "Epoch 5/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.1171 - val_loss: 0.1016\n",
      "Epoch 6/250\n",
      "282/282 [==============================] - 0s 165us/sample - loss: 0.1045 - val_loss: 0.0891\n",
      "Epoch 7/250\n",
      "282/282 [==============================] - 0s 167us/sample - loss: 0.0928 - val_loss: 0.0760\n",
      "Epoch 8/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0811 - val_loss: 0.0629\n",
      "Epoch 9/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0656 - val_loss: 0.0511\n",
      "Epoch 10/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0533 - val_loss: 0.0417\n",
      "Epoch 11/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.0460 - val_loss: 0.0374\n",
      "Epoch 12/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0458 - val_loss: 0.0374\n",
      "Epoch 13/250\n",
      "282/282 [==============================] - 0s 152us/sample - loss: 0.0453 - val_loss: 0.0377\n",
      "Epoch 14/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0499 - val_loss: 0.0371\n",
      "Epoch 15/250\n",
      "282/282 [==============================] - 0s 168us/sample - loss: 0.0438 - val_loss: 0.0368\n",
      "Epoch 16/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0424 - val_loss: 0.0370\n",
      "Epoch 17/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0457 - val_loss: 0.0372\n",
      "Epoch 18/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0468 - val_loss: 0.0372\n",
      "Epoch 19/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0436 - val_loss: 0.0368\n",
      "Epoch 20/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0470 - val_loss: 0.0364\n",
      "Epoch 21/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0448 - val_loss: 0.0360\n",
      "Epoch 22/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0417 - val_loss: 0.0357\n",
      "Epoch 23/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0455 - val_loss: 0.0355\n",
      "Epoch 24/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0411 - val_loss: 0.0353\n",
      "Epoch 25/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0440 - val_loss: 0.0351\n",
      "Epoch 26/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0432 - val_loss: 0.0350\n",
      "Epoch 27/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0456 - val_loss: 0.0349\n",
      "Epoch 28/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0427 - val_loss: 0.0349\n",
      "Epoch 29/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0411 - val_loss: 0.0347\n",
      "Epoch 30/250\n",
      "282/282 [==============================] - 0s 167us/sample - loss: 0.0450 - val_loss: 0.0344\n",
      "Epoch 31/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0422 - val_loss: 0.0340\n",
      "Epoch 32/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0413 - val_loss: 0.0337\n",
      "Epoch 33/250\n",
      "282/282 [==============================] - 0s 158us/sample - loss: 0.0433 - val_loss: 0.0334\n",
      "Epoch 34/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0410 - val_loss: 0.0331\n",
      "Epoch 35/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0424 - val_loss: 0.0328\n",
      "Epoch 36/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0406 - val_loss: 0.0325\n",
      "Epoch 37/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0410 - val_loss: 0.0322\n",
      "Epoch 38/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0396 - val_loss: 0.0319\n",
      "Epoch 39/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0403 - val_loss: 0.0318\n",
      "Epoch 40/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0416 - val_loss: 0.0316\n",
      "Epoch 41/250\n",
      "282/282 [==============================] - 0s 167us/sample - loss: 0.0392 - val_loss: 0.0313\n",
      "Epoch 42/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0431 - val_loss: 0.0310\n",
      "Epoch 43/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0429 - val_loss: 0.0306\n",
      "Epoch 44/250\n",
      "282/282 [==============================] - 0s 165us/sample - loss: 0.0424 - val_loss: 0.0304\n",
      "Epoch 45/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0393 - val_loss: 0.0301\n",
      "Epoch 46/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0425 - val_loss: 0.0297\n",
      "Epoch 47/250\n",
      "282/282 [==============================] - 0s 152us/sample - loss: 0.0405 - val_loss: 0.0295\n",
      "Epoch 48/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0377 - val_loss: 0.0292\n",
      "Epoch 49/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0422 - val_loss: 0.0289\n",
      "Epoch 50/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0387 - val_loss: 0.0287\n",
      "Epoch 51/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0436 - val_loss: 0.0287\n",
      "Epoch 52/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0402 - val_loss: 0.0289\n",
      "Epoch 53/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0406 - val_loss: 0.0286\n",
      "Epoch 54/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0373 - val_loss: 0.0282\n",
      "Epoch 55/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0385 - val_loss: 0.0278\n",
      "Epoch 56/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0388 - val_loss: 0.0276\n",
      "Epoch 57/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0396 - val_loss: 0.0274\n",
      "Epoch 58/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0385 - val_loss: 0.0273\n",
      "Epoch 59/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0378 - val_loss: 0.0274\n",
      "Epoch 60/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0393 - val_loss: 0.0279\n",
      "Epoch 61/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0405 - val_loss: 0.0276\n",
      "Epoch 62/250\n",
      "282/282 [==============================] - 0s 158us/sample - loss: 0.0377 - val_loss: 0.0273\n",
      "Epoch 63/250\n",
      "282/282 [==============================] - 0s 158us/sample - loss: 0.0385 - val_loss: 0.0270\n",
      "Epoch 64/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0378 - val_loss: 0.0269\n",
      "Epoch 65/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0367 - val_loss: 0.0268\n",
      "Epoch 66/250\n",
      "282/282 [==============================] - 0s 167us/sample - loss: 0.0373 - val_loss: 0.0266\n",
      "Epoch 67/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0358 - val_loss: 0.0265\n",
      "Epoch 68/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0397 - val_loss: 0.0264\n",
      "Epoch 69/250\n",
      "282/282 [==============================] - 0s 167us/sample - loss: 0.0394 - val_loss: 0.0264\n",
      "Epoch 70/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0385 - val_loss: 0.0265\n",
      "Epoch 71/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0375 - val_loss: 0.0263\n",
      "Epoch 72/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0389 - val_loss: 0.0262\n",
      "Epoch 73/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0410 - val_loss: 0.0262\n",
      "Epoch 74/250\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.033 - 0s 160us/sample - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 75/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0395 - val_loss: 0.0261\n",
      "Epoch 76/250\n",
      "282/282 [==============================] - 0s 220us/sample - loss: 0.0409 - val_loss: 0.0262\n",
      "Epoch 77/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0365 - val_loss: 0.0263\n",
      "Epoch 78/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0393 - val_loss: 0.0261\n",
      "Epoch 79/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0382 - val_loss: 0.0261\n",
      "Epoch 80/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0409 - val_loss: 0.0261\n",
      "Epoch 81/250\n",
      "282/282 [==============================] - 0s 165us/sample - loss: 0.0388 - val_loss: 0.0263\n",
      "Epoch 82/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0365 - val_loss: 0.0266\n",
      "Epoch 83/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0352 - val_loss: 0.0265\n",
      "Epoch 84/250\n",
      "282/282 [==============================] - 0s 167us/sample - loss: 0.0384 - val_loss: 0.0264\n",
      "Epoch 85/250\n",
      "282/282 [==============================] - 0s 160us/sample - loss: 0.0358 - val_loss: 0.0262\n",
      "Epoch 86/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 87/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 88/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0361 - val_loss: 0.0259\n",
      "Epoch 89/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0378 - val_loss: 0.0259\n",
      "Epoch 90/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 91/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 92/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0357 - val_loss: 0.0259\n",
      "Epoch 93/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0369 - val_loss: 0.0258\n",
      "Epoch 94/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0350 - val_loss: 0.0258\n",
      "Epoch 95/250\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.030 - 0s 159us/sample - loss: 0.0366 - val_loss: 0.0257\n",
      "Epoch 96/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0391 - val_loss: 0.0258\n",
      "Epoch 97/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0378 - val_loss: 0.0258\n",
      "Epoch 98/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0362 - val_loss: 0.0258\n",
      "Epoch 99/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0349 - val_loss: 0.0258\n",
      "Epoch 100/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0363 - val_loss: 0.0256\n",
      "Epoch 101/250\n",
      "282/282 [==============================] - 0s 180us/sample - loss: 0.0379 - val_loss: 0.0256\n",
      "Epoch 102/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0386 - val_loss: 0.0255\n",
      "Epoch 103/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0356 - val_loss: 0.0257\n",
      "Epoch 104/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0377 - val_loss: 0.0259\n",
      "Epoch 105/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0341 - val_loss: 0.0258\n",
      "Epoch 106/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0351 - val_loss: 0.0258\n",
      "Epoch 107/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0383 - val_loss: 0.0259\n",
      "Epoch 108/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0381 - val_loss: 0.0257\n",
      "Epoch 109/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0358 - val_loss: 0.0257\n",
      "Epoch 110/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0355 - val_loss: 0.0257\n",
      "Epoch 111/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0365 - val_loss: 0.0258\n",
      "Epoch 112/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0364 - val_loss: 0.0258\n",
      "Epoch 113/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 114/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0359 - val_loss: 0.0258\n",
      "Epoch 115/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0381 - val_loss: 0.0258\n",
      "Epoch 116/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0354 - val_loss: 0.0258\n",
      "Epoch 117/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0356 - val_loss: 0.0258\n",
      "Epoch 118/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0354 - val_loss: 0.0258\n",
      "Epoch 119/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0378 - val_loss: 0.0261\n",
      "Epoch 120/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0384 - val_loss: 0.0263\n",
      "Epoch 121/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0367 - val_loss: 0.0262\n",
      "Epoch 122/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0354 - val_loss: 0.0262\n",
      "Epoch 123/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0342 - val_loss: 0.0262\n",
      "Epoch 124/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0367 - val_loss: 0.0261\n",
      "Epoch 125/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0351 - val_loss: 0.0260\n",
      "Epoch 126/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0344 - val_loss: 0.0260\n",
      "Epoch 127/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0354 - val_loss: 0.0259\n",
      "Epoch 128/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0359 - val_loss: 0.0259\n",
      "Epoch 129/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0356 - val_loss: 0.0258\n",
      "Epoch 130/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0355 - val_loss: 0.0259\n",
      "Epoch 131/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 132/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0374 - val_loss: 0.0259\n",
      "Epoch 133/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0358 - val_loss: 0.0259\n",
      "Epoch 134/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0350 - val_loss: 0.0259\n",
      "Epoch 135/250\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0364 - val_loss: 0.0259\n",
      "Epoch 136/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0363 - val_loss: 0.0259\n",
      "Epoch 137/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0346 - val_loss: 0.0258\n",
      "Epoch 138/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0362 - val_loss: 0.0257\n",
      "Epoch 139/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0376 - val_loss: 0.0258\n",
      "Epoch 140/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0365 - val_loss: 0.0258\n",
      "Epoch 141/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 142/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0391 - val_loss: 0.0258\n",
      "Epoch 143/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0365 - val_loss: 0.0258\n",
      "Epoch 144/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.0351 - val_loss: 0.0258\n",
      "Epoch 145/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0359 - val_loss: 0.0259\n",
      "Epoch 146/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0338 - val_loss: 0.0259\n",
      "Epoch 147/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0343 - val_loss: 0.0259\n",
      "Epoch 148/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0376 - val_loss: 0.0260\n",
      "Epoch 149/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0351 - val_loss: 0.0260\n",
      "Epoch 150/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0349 - val_loss: 0.0260\n",
      "Epoch 151/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 152/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0360 - val_loss: 0.0261\n",
      "Epoch 153/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0358 - val_loss: 0.0260\n",
      "Epoch 154/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0355 - val_loss: 0.0260\n",
      "Epoch 155/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0361 - val_loss: 0.0260\n",
      "Epoch 156/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0358 - val_loss: 0.0259\n",
      "Epoch 157/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 158/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0351 - val_loss: 0.0259\n",
      "Epoch 159/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0377 - val_loss: 0.0259\n",
      "Epoch 160/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0337 - val_loss: 0.0259\n",
      "Epoch 161/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0383 - val_loss: 0.0260\n",
      "Epoch 162/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0350 - val_loss: 0.0262\n",
      "Epoch 163/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0358 - val_loss: 0.0264\n",
      "Epoch 164/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0353 - val_loss: 0.0265\n",
      "Epoch 165/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0390 - val_loss: 0.0265\n",
      "Epoch 166/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0357 - val_loss: 0.0264\n",
      "Epoch 167/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.0362 - val_loss: 0.0263\n",
      "Epoch 168/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0375 - val_loss: 0.0261\n",
      "Epoch 169/250\n",
      "282/282 [==============================] - 0s 216us/sample - loss: 0.0344 - val_loss: 0.0261\n",
      "Epoch 170/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0362 - val_loss: 0.0259\n",
      "Epoch 171/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0343 - val_loss: 0.0258\n",
      "Epoch 172/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 173/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0361 - val_loss: 0.0260\n",
      "Epoch 174/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0359 - val_loss: 0.0261\n",
      "Epoch 175/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0348 - val_loss: 0.0261\n",
      "Epoch 176/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.0355 - val_loss: 0.0261\n",
      "Epoch 177/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0377 - val_loss: 0.0261\n",
      "Epoch 178/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0346 - val_loss: 0.0261\n",
      "Epoch 179/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0344 - val_loss: 0.0261\n",
      "Epoch 180/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0381 - val_loss: 0.0261\n",
      "Epoch 181/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0355 - val_loss: 0.0261\n",
      "Epoch 182/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0359 - val_loss: 0.0260\n",
      "Epoch 183/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 184/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0358 - val_loss: 0.0261\n",
      "Epoch 185/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.0356 - val_loss: 0.0261\n",
      "Epoch 186/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 187/250\n",
      "282/282 [==============================] - 0s 168us/sample - loss: 0.0353 - val_loss: 0.0260\n",
      "Epoch 188/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0348 - val_loss: 0.0259\n",
      "Epoch 189/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0372 - val_loss: 0.0258\n",
      "Epoch 190/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 191/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0340 - val_loss: 0.0258\n",
      "Epoch 192/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0344 - val_loss: 0.0257\n",
      "Epoch 193/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0362 - val_loss: 0.0257\n",
      "Epoch 194/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.0358 - val_loss: 0.0257\n",
      "Epoch 195/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0350 - val_loss: 0.0256\n",
      "Epoch 196/250\n",
      "282/282 [==============================] - 0s 168us/sample - loss: 0.0340 - val_loss: 0.0256\n",
      "Epoch 197/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0352 - val_loss: 0.0256\n",
      "Epoch 198/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0338 - val_loss: 0.0256\n",
      "Epoch 199/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0356 - val_loss: 0.0257\n",
      "Epoch 200/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0353 - val_loss: 0.0257\n",
      "Epoch 201/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0347 - val_loss: 0.0258\n",
      "Epoch 202/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0351 - val_loss: 0.0259\n",
      "Epoch 203/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0354 - val_loss: 0.0259\n",
      "Epoch 204/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0355 - val_loss: 0.0259\n",
      "Epoch 205/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0349 - val_loss: 0.0259\n",
      "Epoch 206/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0352 - val_loss: 0.0259\n",
      "Epoch 207/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0335 - val_loss: 0.0259\n",
      "Epoch 208/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0379 - val_loss: 0.0258\n",
      "Epoch 209/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0333 - val_loss: 0.0259\n",
      "Epoch 210/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0362 - val_loss: 0.0259\n",
      "Epoch 211/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0354 - val_loss: 0.0259\n",
      "Epoch 212/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0339 - val_loss: 0.0259\n",
      "Epoch 213/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0350 - val_loss: 0.0258\n",
      "Epoch 214/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0336 - val_loss: 0.0257\n",
      "Epoch 215/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0352 - val_loss: 0.0256\n",
      "Epoch 216/250\n",
      "282/282 [==============================] - 0s 154us/sample - loss: 0.0352 - val_loss: 0.0256\n",
      "Epoch 217/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0332 - val_loss: 0.0256\n",
      "Epoch 218/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0356 - val_loss: 0.0256\n",
      "Epoch 219/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0330 - val_loss: 0.0255\n",
      "Epoch 220/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0340 - val_loss: 0.0255\n",
      "Epoch 221/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0360 - val_loss: 0.0255\n",
      "Epoch 222/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0343 - val_loss: 0.0255\n",
      "Epoch 223/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0343 - val_loss: 0.0256\n",
      "Epoch 224/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0353 - val_loss: 0.0256\n",
      "Epoch 225/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 226/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0345 - val_loss: 0.0258\n",
      "Epoch 227/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0345 - val_loss: 0.0258\n",
      "Epoch 228/250\n",
      "282/282 [==============================] - 0s 168us/sample - loss: 0.0345 - val_loss: 0.0257\n",
      "Epoch 229/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0347 - val_loss: 0.0258\n",
      "Epoch 230/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0351 - val_loss: 0.0257\n",
      "Epoch 231/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0364 - val_loss: 0.0257\n",
      "Epoch 232/250\n",
      "282/282 [==============================] - 0s 164us/sample - loss: 0.0332 - val_loss: 0.0257\n",
      "Epoch 233/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0353 - val_loss: 0.0257\n",
      "Epoch 234/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0337 - val_loss: 0.0257\n",
      "Epoch 235/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0353 - val_loss: 0.0259\n",
      "Epoch 236/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0349 - val_loss: 0.0259\n",
      "Epoch 237/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0353 - val_loss: 0.0258\n",
      "Epoch 238/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0364 - val_loss: 0.0259\n",
      "Epoch 239/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0343 - val_loss: 0.0258\n",
      "Epoch 240/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0332 - val_loss: 0.0258\n",
      "Epoch 241/250\n",
      "282/282 [==============================] - 0s 157us/sample - loss: 0.0354 - val_loss: 0.0258\n",
      "Epoch 242/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0346 - val_loss: 0.0258\n",
      "Epoch 243/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0362 - val_loss: 0.0258\n",
      "Epoch 244/250\n",
      "282/282 [==============================] - 0s 159us/sample - loss: 0.0354 - val_loss: 0.0260\n",
      "Epoch 245/250\n",
      "282/282 [==============================] - 0s 161us/sample - loss: 0.0350 - val_loss: 0.0259\n",
      "Epoch 246/250\n",
      "282/282 [==============================] - 0s 156us/sample - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 247/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.0357 - val_loss: 0.0258\n",
      "Epoch 248/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0354 - val_loss: 0.0259\n",
      "Epoch 249/250\n",
      "282/282 [==============================] - 0s 168us/sample - loss: 0.0359 - val_loss: 0.0260\n",
      "Epoch 250/250\n",
      "282/282 [==============================] - 0s 163us/sample - loss: 0.0343 - val_loss: 0.0261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fb0595ab48>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "# YOUR CODE HERE!\n",
    "batch_size = 60\n",
    "epochs = 250\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 86us/sample - loss: 0.0908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0908465517079172"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# YOUR CODE HERE!\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "# YOUR CODE HERE!\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 1)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted = predicted.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3670.919922</td>\n",
       "      <td>7267.738281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3670.919922</td>\n",
       "      <td>7138.959473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3912.570068</td>\n",
       "      <td>6949.926270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3924.239990</td>\n",
       "      <td>8666.452148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3974.050049</td>\n",
       "      <td>8816.033203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Real    Predicted\n",
       "0  3670.919922  7267.738281\n",
       "1  3670.919922  7138.959473\n",
       "2  3912.570068  6949.926270\n",
       "3  3924.239990  8666.452148\n",
       "4  3974.050049  8816.033203"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "btc_fng = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "})\n",
    "btc_fng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fb06ccf488>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "# YOUR CODE HERE!\n",
    "btc_fng.plot(title='BTC predictions using FNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
