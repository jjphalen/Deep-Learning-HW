{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Closing Prices\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin closing prices to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value\n",
       "date                  \n",
       "2019-07-29          19\n",
       "2019-07-28          16\n",
       "2019-07-27          47\n",
       "2019-07-26          24\n",
       "2019-07-25          42"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2019-07-25    9882.429688\n",
       "2019-07-26    9847.450195\n",
       "2019-07-27    9478.320313\n",
       "2019-07-28    9531.769531\n",
       "2019-07-29    9529.889648\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the historical closing prices for bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "      <td>9882.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "      <td>9847.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "      <td>9478.320313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "      <td>9531.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "      <td>9529.889648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2019-07-25          42  9882.429688\n",
       "2019-07-26          24  9847.450195\n",
       "2019-07-27          47  9478.320313\n",
       "2019-07-28          16  9531.769531\n",
       "2019-07-29          19  9529.889648"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>30</td>\n",
       "      <td>9114.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>15</td>\n",
       "      <td>8870.820313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-03</th>\n",
       "      <td>40</td>\n",
       "      <td>9251.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8218.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>11</td>\n",
       "      <td>6937.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2018-02-01          30  9114.719727\n",
       "2018-02-02          15  8870.820313\n",
       "2018-02-03          40  9251.269531\n",
       "2018-02-04          24  8218.049805\n",
       "2018-02-05          11  6937.080078"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous closing prices\n",
    "# Try a window size anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 1\n",
    "\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 1\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9114.719727],\n",
       "       [ 8870.820313],\n",
       "       [ 9251.269531],\n",
       "       [ 8218.049805],\n",
       "       [ 6937.080078],\n",
       "       [ 7701.25    ],\n",
       "       [ 7592.720215],\n",
       "       [ 8260.69043 ],\n",
       "       [ 8696.830078],\n",
       "       [ 8569.290039],\n",
       "       [ 8084.609863],\n",
       "       [ 8911.269531],\n",
       "       [ 8544.69043 ],\n",
       "       [ 9485.639648],\n",
       "       [10033.75    ],\n",
       "       [10188.730469],\n",
       "       [11097.209961],\n",
       "       [10417.230469],\n",
       "       [11182.280273],\n",
       "       [11256.429688],\n",
       "       [10481.660156],\n",
       "       [ 9847.959961],\n",
       "       [10175.509766],\n",
       "       [ 9705.730469],\n",
       "       [ 9610.110352],\n",
       "       [10326.5     ],\n",
       "       [10594.759766],\n",
       "       [10334.44043 ],\n",
       "       [10929.370117],\n",
       "       [11043.120117],\n",
       "       [11465.360352],\n",
       "       [11504.419922],\n",
       "       [11440.730469],\n",
       "       [10735.450195],\n",
       "       [ 9928.55957 ],\n",
       "       [ 9316.719727],\n",
       "       [ 9252.759766],\n",
       "       [ 8797.269531],\n",
       "       [ 9544.839844],\n",
       "       [ 9142.150391],\n",
       "       [ 9160.120117],\n",
       "       [ 8217.700195],\n",
       "       [ 8268.410156],\n",
       "       [ 8283.230469],\n",
       "       [ 7883.450195],\n",
       "       [ 8215.400391],\n",
       "       [ 8623.139648],\n",
       "       [ 8920.709961],\n",
       "       [ 8911.349609],\n",
       "       [ 8724.980469],\n",
       "       [ 8934.799805],\n",
       "       [ 8548.05957 ],\n",
       "       [ 8472.839844],\n",
       "       [ 8152.200195],\n",
       "       [ 7808.47998 ],\n",
       "       [ 7959.779785],\n",
       "       [ 7106.620117],\n",
       "       [ 6853.759766],\n",
       "       [ 6943.77002 ],\n",
       "       [ 6835.839844],\n",
       "       [ 7074.600098],\n",
       "       [ 7434.299805],\n",
       "       [ 6815.5     ],\n",
       "       [ 6790.450195],\n",
       "       [ 6634.859863],\n",
       "       [ 6917.200195],\n",
       "       [ 7049.919922],\n",
       "       [ 6789.529785],\n",
       "       [ 6871.069824],\n",
       "       [ 6977.129883],\n",
       "       [ 7927.72998 ],\n",
       "       [ 7899.109863],\n",
       "       [ 7921.629883],\n",
       "       [ 8189.959961],\n",
       "       [ 8301.820313],\n",
       "       [ 8877.080078],\n",
       "       [ 8935.719727],\n",
       "       [ 8823.360352],\n",
       "       [ 8968.25    ],\n",
       "       [ 9655.769531],\n",
       "       [ 8873.620117],\n",
       "       [ 9282.120117],\n",
       "       [ 8938.469727],\n",
       "       [ 9351.469727],\n",
       "       [ 9407.040039],\n",
       "       [ 9248.450195],\n",
       "       [ 9077.280273],\n",
       "       [ 9232.19043 ],\n",
       "       [ 9745.040039],\n",
       "       [ 9699.610352],\n",
       "       [ 9845.900391],\n",
       "       [ 9644.919922],\n",
       "       [ 9377.80957 ],\n",
       "       [ 9196.129883],\n",
       "       [ 9321.160156],\n",
       "       [ 9032.219727],\n",
       "       [ 8421.      ],\n",
       "       [ 8486.669922],\n",
       "       [ 8709.459961],\n",
       "       [ 8672.900391],\n",
       "       [ 8480.160156],\n",
       "       [ 8344.780273],\n",
       "       [ 8071.040039],\n",
       "       [ 8247.910156],\n",
       "       [ 8249.240234],\n",
       "       [ 8533.      ],\n",
       "       [ 8419.650391],\n",
       "       [ 7992.75    ],\n",
       "       [ 7505.77002 ],\n",
       "       [ 7584.740234],\n",
       "       [ 7475.359863],\n",
       "       [ 7355.060059],\n",
       "       [ 7362.22998 ],\n",
       "       [ 7118.879883],\n",
       "       [ 7474.75    ],\n",
       "       [ 7393.02002 ],\n",
       "       [ 7502.149902],\n",
       "       [ 7530.549805],\n",
       "       [ 7643.259766],\n",
       "       [ 7719.75    ],\n",
       "       [ 7503.200195],\n",
       "       [ 7629.399902],\n",
       "       [ 7661.790039],\n",
       "       [ 7700.109863],\n",
       "       [ 7627.52002 ],\n",
       "       [ 7513.689941],\n",
       "       [ 6773.720215],\n",
       "       [ 6887.370117],\n",
       "       [ 6556.939941],\n",
       "       [ 6310.430176],\n",
       "       [ 6643.259766],\n",
       "       [ 6396.709961],\n",
       "       [ 6503.100098],\n",
       "       [ 6457.779785],\n",
       "       [ 6714.819824],\n",
       "       [ 6741.279785],\n",
       "       [ 6761.27002 ],\n",
       "       [ 6720.640137],\n",
       "       [ 6051.470215],\n",
       "       [ 6166.540039],\n",
       "       [ 6157.779785],\n",
       "       [ 6260.350098],\n",
       "       [ 6088.390137],\n",
       "       [ 6141.569824],\n",
       "       [ 5871.279785],\n",
       "       [ 6203.799805],\n",
       "       [ 6385.379883],\n",
       "       [ 6339.040039],\n",
       "       [ 6615.660156],\n",
       "       [ 6509.580078],\n",
       "       [ 6590.060059],\n",
       "       [ 6534.810059],\n",
       "       [ 6602.02002 ],\n",
       "       [ 6758.080078],\n",
       "       [ 6707.379883],\n",
       "       [ 6668.839844],\n",
       "       [ 6306.850098],\n",
       "       [ 6394.359863],\n",
       "       [ 6253.600098],\n",
       "       [ 6229.830078],\n",
       "       [ 6268.75    ],\n",
       "       [ 6364.259766],\n",
       "       [ 6740.549805],\n",
       "       [ 7326.700195],\n",
       "       [ 7383.390137],\n",
       "       [ 7477.5     ],\n",
       "       [ 7333.930176],\n",
       "       [ 7405.399902],\n",
       "       [ 7398.640137],\n",
       "       [ 7718.      ],\n",
       "       [ 8395.820313],\n",
       "       [ 8170.22998 ],\n",
       "       [ 7937.25    ],\n",
       "       [ 8182.890137],\n",
       "       [ 8230.870117],\n",
       "       [ 8216.780273],\n",
       "       [ 8176.060059],\n",
       "       [ 7735.299805],\n",
       "       [ 7610.899902],\n",
       "       [ 7542.339844],\n",
       "       [ 7417.600098],\n",
       "       [ 7017.890137],\n",
       "       [ 7042.390137],\n",
       "       [ 6945.779785],\n",
       "       [ 6723.209961],\n",
       "       [ 6285.02002 ],\n",
       "       [ 6543.240234],\n",
       "       [ 6153.410156],\n",
       "       [ 6242.540039],\n",
       "       [ 6322.919922],\n",
       "       [ 6263.200195],\n",
       "       [ 6199.600098],\n",
       "       [ 6274.220215],\n",
       "       [ 6323.810059],\n",
       "       [ 6591.160156],\n",
       "       [ 6405.709961],\n",
       "       [ 6502.180176],\n",
       "       [ 6269.899902],\n",
       "       [ 6491.109863],\n",
       "       [ 6366.129883],\n",
       "       [ 6538.950195],\n",
       "       [ 6708.959961],\n",
       "       [ 6749.560059],\n",
       "       [ 6720.600098],\n",
       "       [ 6915.72998 ],\n",
       "       [ 7091.379883],\n",
       "       [ 7052.      ],\n",
       "       [ 6998.759766],\n",
       "       [ 7026.959961],\n",
       "       [ 7203.459961],\n",
       "       [ 7301.259766],\n",
       "       [ 7270.049805],\n",
       "       [ 7369.859863],\n",
       "       [ 6705.029785],\n",
       "       [ 6515.419922],\n",
       "       [ 6411.779785],\n",
       "       [ 6200.160156],\n",
       "       [ 6249.069824],\n",
       "       [ 6324.430176],\n",
       "       [ 6295.540039],\n",
       "       [ 6337.109863],\n",
       "       [ 6492.      ],\n",
       "       [ 6486.009766],\n",
       "       [ 6522.080078],\n",
       "       [ 6502.439941],\n",
       "       [ 6261.47998 ],\n",
       "       [ 6346.439941],\n",
       "       [ 6398.799805],\n",
       "       [ 6505.899902],\n",
       "       [ 6762.060059],\n",
       "       [ 6716.600098],\n",
       "       [ 6702.700195],\n",
       "       [ 6583.529785],\n",
       "       [ 6437.740234],\n",
       "       [ 6462.600098],\n",
       "       [ 6686.129883],\n",
       "       [ 6635.379883],\n",
       "       [ 6603.75    ],\n",
       "       [ 6623.709961],\n",
       "       [ 6594.97998 ],\n",
       "       [ 6525.470215],\n",
       "       [ 6492.259766],\n",
       "       [ 6579.790039],\n",
       "       [ 6632.870117],\n",
       "       [ 6589.939941],\n",
       "       [ 6601.149902],\n",
       "       [ 6650.069824],\n",
       "       [ 6631.790039],\n",
       "       [ 6581.069824],\n",
       "       [ 6209.470215],\n",
       "       [ 6250.850098],\n",
       "       [ 6267.27002 ],\n",
       "       [ 6277.72998 ],\n",
       "       [ 6612.359863],\n",
       "       [ 6583.049805],\n",
       "       [ 6574.52002 ],\n",
       "       [ 6488.720215],\n",
       "       [ 6469.279785],\n",
       "       [ 6490.560059],\n",
       "       [ 6509.870117],\n",
       "       [ 6483.22998 ],\n",
       "       [ 6470.220215],\n",
       "       [ 6476.25    ],\n",
       "       [ 6462.77002 ],\n",
       "       [ 6457.209961],\n",
       "       [ 6470.169922],\n",
       "       [ 6470.740234],\n",
       "       [ 6313.910156],\n",
       "       [ 6309.109863],\n",
       "       [ 6342.609863],\n",
       "       [ 6381.299805],\n",
       "       [ 6394.660156],\n",
       "       [ 6376.319824],\n",
       "       [ 6467.049805],\n",
       "       [ 6433.740234],\n",
       "       [ 6479.720215],\n",
       "       [ 6529.680176],\n",
       "       [ 6446.060059],\n",
       "       [ 6377.990234],\n",
       "       [ 6396.370117],\n",
       "       [ 6408.180176],\n",
       "       [ 6375.080078],\n",
       "       [ 6339.169922],\n",
       "       [ 5741.470215],\n",
       "       [ 5647.5     ],\n",
       "       [ 5586.27002 ],\n",
       "       [ 5568.939941],\n",
       "       [ 5615.259766],\n",
       "       [ 4809.620117],\n",
       "       [ 4441.810059],\n",
       "       [ 4593.040039],\n",
       "       [ 4320.680176],\n",
       "       [ 4343.419922],\n",
       "       [ 3854.110107],\n",
       "       [ 4004.149902],\n",
       "       [ 3784.590088],\n",
       "       [ 3822.98999 ],\n",
       "       [ 4263.549805],\n",
       "       [ 4286.689941],\n",
       "       [ 4009.669922],\n",
       "       [ 4197.459961],\n",
       "       [ 4143.859863],\n",
       "       [ 3871.409912],\n",
       "       [ 3948.439941],\n",
       "       [ 3737.530029],\n",
       "       [ 3485.179932],\n",
       "       [ 3420.570068],\n",
       "       [ 3461.070068],\n",
       "       [ 3592.840088],\n",
       "       [ 3467.159912],\n",
       "       [ 3401.02002 ],\n",
       "       [ 3485.590088],\n",
       "       [ 3305.110107],\n",
       "       [ 3235.47998 ],\n",
       "       [ 3232.51001 ],\n",
       "       [ 3255.370117],\n",
       "       [ 3548.189941],\n",
       "       [ 3715.850098],\n",
       "       [ 3736.540039],\n",
       "       [ 4137.660156],\n",
       "       [ 3898.810059],\n",
       "       [ 4045.23999 ],\n",
       "       [ 4007.629883],\n",
       "       [ 4081.949951],\n",
       "       [ 3834.72998 ],\n",
       "       [ 3848.780029],\n",
       "       [ 3646.090088],\n",
       "       [ 3947.860107],\n",
       "       [ 3797.060059],\n",
       "       [ 3896.209961],\n",
       "       [ 3747.389893],\n",
       "       [ 3880.149902],\n",
       "       [ 3961.01001 ],\n",
       "       [ 3835.860107],\n",
       "       [ 3874.060059],\n",
       "       [ 3855.389893],\n",
       "       [ 4102.850098],\n",
       "       [ 4050.399902],\n",
       "       [ 4040.75    ],\n",
       "       [ 4048.340088],\n",
       "       [ 3668.149902],\n",
       "       [ 3669.199951],\n",
       "       [ 3664.379883],\n",
       "       [ 3551.23999 ],\n",
       "       [ 3703.899902],\n",
       "       [ 3621.23999 ],\n",
       "       [ 3643.98999 ],\n",
       "       [ 3685.300049],\n",
       "       [ 3648.050049],\n",
       "       [ 3729.780029],\n",
       "       [ 3567.72998 ],\n",
       "       [ 3571.919922],\n",
       "       [ 3602.040039],\n",
       "       [ 3572.050049],\n",
       "       [ 3598.52002 ],\n",
       "       [ 3582.889893],\n",
       "       [ 3596.5     ],\n",
       "       [ 3565.080078],\n",
       "       [ 3453.419922],\n",
       "       [ 3418.25    ],\n",
       "       [ 3467.209961],\n",
       "       [ 3467.209961],\n",
       "       [ 3434.129883],\n",
       "       [ 3461.629883],\n",
       "       [ 3508.679932],\n",
       "       [ 3449.620117],\n",
       "       [ 3431.23999 ],\n",
       "       [ 3447.659912],\n",
       "       [ 3394.889893],\n",
       "       [ 3375.330078],\n",
       "       [ 3660.030029],\n",
       "       [ 3652.26001 ],\n",
       "       [ 3685.139893],\n",
       "       [ 3611.340088],\n",
       "       [ 3617.409912],\n",
       "       [ 3605.870117],\n",
       "       [ 3588.719971],\n",
       "       [ 3593.48999 ],\n",
       "       [ 3617.23999 ],\n",
       "       [ 3670.919922],\n",
       "       [ 3670.919922],\n",
       "       [ 3912.570068],\n",
       "       [ 3924.23999 ],\n",
       "       [ 3974.050049],\n",
       "       [ 3937.040039],\n",
       "       [ 3983.530029],\n",
       "       [ 4149.089844],\n",
       "       [ 3771.620117],\n",
       "       [ 3845.51001 ],\n",
       "       [ 3817.879883],\n",
       "       [ 3830.719971],\n",
       "       [ 3823.370117],\n",
       "       [ 3831.47998 ],\n",
       "       [ 3842.939941],\n",
       "       [ 3812.310059],\n",
       "       [ 3731.280029],\n",
       "       [ 3874.179932],\n",
       "       [ 3874.97998 ],\n",
       "       [ 3882.610107],\n",
       "       [ 3868.02002 ],\n",
       "       [ 3947.73999 ],\n",
       "       [ 3929.840088],\n",
       "       [ 3874.889893],\n",
       "       [ 3888.570068],\n",
       "       [ 3878.439941],\n",
       "       [ 3881.439941],\n",
       "       [ 3927.080078],\n",
       "       [ 4027.01001 ],\n",
       "       [ 3998.      ],\n",
       "       [ 3988.850098],\n",
       "       [ 4024.139893],\n",
       "       [ 4056.75    ],\n",
       "       [ 3996.929932],\n",
       "       [ 4000.840088],\n",
       "       [ 4007.209961],\n",
       "       [ 3994.110107],\n",
       "       [ 3924.550049],\n",
       "       [ 3942.219971],\n",
       "       [ 4045.97998 ],\n",
       "       [ 4036.449951],\n",
       "       [ 4111.379883],\n",
       "       [ 4118.129883],\n",
       "       [ 4112.689941],\n",
       "       [ 4151.319824],\n",
       "       [ 4906.930176],\n",
       "       [ 4976.589844],\n",
       "       [ 4913.359863],\n",
       "       [ 5047.22998 ],\n",
       "       [ 5057.25    ],\n",
       "       [ 5201.160156],\n",
       "       [ 5294.089844],\n",
       "       [ 5201.299805],\n",
       "       [ 5318.600098],\n",
       "       [ 5048.560059],\n",
       "       [ 5081.5     ],\n",
       "       [ 5080.660156],\n",
       "       [ 5165.589844],\n",
       "       [ 5037.27002 ],\n",
       "       [ 5212.810059],\n",
       "       [ 5236.259766],\n",
       "       [ 5289.75    ],\n",
       "       [ 5295.529785],\n",
       "       [ 5326.180176],\n",
       "       [ 5305.740234],\n",
       "       [ 5394.669922],\n",
       "       [ 5539.100098],\n",
       "       [ 5454.580078],\n",
       "       [ 5162.669922],\n",
       "       [ 5234.089844],\n",
       "       [ 5229.47998 ],\n",
       "       [ 5272.450195],\n",
       "       [ 5237.959961],\n",
       "       [ 5350.640137],\n",
       "       [ 5389.540039],\n",
       "       [ 5500.720215],\n",
       "       [ 5753.379883],\n",
       "       [ 5840.080078],\n",
       "       [ 5794.140137],\n",
       "       [ 5748.169922],\n",
       "       [ 5819.569824],\n",
       "       [ 5998.709961],\n",
       "       [ 6171.959961],\n",
       "       [ 6358.290039],\n",
       "       [ 7191.359863],\n",
       "       [ 6977.629883],\n",
       "       [ 7806.359863],\n",
       "       [ 7980.129883],\n",
       "       [ 8183.830078],\n",
       "       [ 7874.109863],\n",
       "       [ 7371.959961],\n",
       "       [ 7266.080078],\n",
       "       [ 8193.139648],\n",
       "       [ 7998.290039],\n",
       "       [ 7947.930176],\n",
       "       [ 7626.890137],\n",
       "       [ 7876.5     ],\n",
       "       [ 7996.399902],\n",
       "       [ 8059.129883],\n",
       "       [ 8726.230469],\n",
       "       [ 8785.169922],\n",
       "       [ 8718.849609],\n",
       "       [ 8664.55957 ],\n",
       "       [ 8276.25    ],\n",
       "       [ 8550.669922],\n",
       "       [ 8555.870117],\n",
       "       [ 8737.910156],\n",
       "       [ 8114.490234],\n",
       "       [ 7677.470215],\n",
       "       [ 7791.290039],\n",
       "       [ 7807.359863],\n",
       "       [ 8002.629883],\n",
       "       [ 7933.779785],\n",
       "       [ 7643.439941],\n",
       "       [ 8021.      ],\n",
       "       [ 7917.319824],\n",
       "       [ 8174.140137],\n",
       "       [ 8235.570313],\n",
       "       [ 8693.959961],\n",
       "       [ 8853.55957 ],\n",
       "       [ 8979.179688],\n",
       "       [ 9336.009766],\n",
       "       [ 9081.709961],\n",
       "       [ 9280.540039],\n",
       "       [ 9536.849609],\n",
       "       [10218.870117],\n",
       "       [10689.540039],\n",
       "       [10855.990234],\n",
       "       [11035.740234],\n",
       "       [11740.339844],\n",
       "       [12913.280273],\n",
       "       [11154.089844],\n",
       "       [12355.05957 ],\n",
       "       [11884.099609],\n",
       "       [10769.049805],\n",
       "       [10591.870117],\n",
       "       [10844.129883],\n",
       "       [11981.610352],\n",
       "       [11156.519531],\n",
       "       [10993.25    ],\n",
       "       [11248.94043 ],\n",
       "       [11474.280273],\n",
       "       [12296.160156],\n",
       "       [12567.019531],\n",
       "       [12099.120117],\n",
       "       [11343.120117],\n",
       "       [11797.370117],\n",
       "       [11363.969727],\n",
       "       [10204.410156],\n",
       "       [10850.259766],\n",
       "       [ 9423.44043 ],\n",
       "       [ 9696.150391],\n",
       "       [10638.349609],\n",
       "       [10532.94043 ],\n",
       "       [10759.419922],\n",
       "       [10586.709961],\n",
       "       [10325.870117],\n",
       "       [ 9854.150391],\n",
       "       [ 9772.139648],\n",
       "       [ 9882.429688],\n",
       "       [ 9847.450195],\n",
       "       [ 9478.320313]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "# YOUR CODE HERE!\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split = int(0.7 *len(X))\n",
    "X_train_rnn = X[: split -1]\n",
    "X_test = X[split:]\n",
    "y_train_rnn = y[: split -1]\n",
    "y_test = y[split:]\n",
    "\n",
    "X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MinMaxScaler to scale the data between 0 and 1. \n",
    "# YOUR CODE HERE!\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train_rnn =scaler.transform(X_train_rnn)\n",
    "X_val_rnn =scaler.transform(X_val_rnn)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "y_train_rnn = scaler.transform(y_train_rnn)\n",
    "y_val_rnn = scaler.transform(y_val_rnn)\n",
    "y_test =scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[0.04500054]]\n",
      "\n",
      " [[0.04416178]]\n",
      "\n",
      " [[0.05318584]]\n",
      "\n",
      " [[0.3722152 ]]\n",
      "\n",
      " [[0.5487353 ]]] \n",
      "\n",
      "X_val_rnn sample values:\n",
      "[[[0.29119173]]\n",
      "\n",
      " [[0.3391166 ]]\n",
      "\n",
      " [[0.68314713]]\n",
      "\n",
      " [[0.32350213]]\n",
      "\n",
      " [[0.49980837]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.03974167]]\n",
      "\n",
      " [[0.04528668]]\n",
      "\n",
      " [[0.04528668]]\n",
      "\n",
      " [[0.07024855]]\n",
      "\n",
      " [[0.07145402]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "# YOUR CODE HERE!\n",
    "X_train_rnn = X_train_rnn.reshape((X_train_rnn.shape[0], X_train_rnn.shape[1], 1))\n",
    "X_val_rnn = X_val_rnn.reshape((X_val_rnn.shape[0], X_val_rnn.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train_rnn[:5]} \\n\")\n",
    "print (f\"X_val_rnn sample values:\\n{X_val_rnn[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# YOUR CODE HERE!\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 30\n",
    "dropout_fraction = 0.5\n",
    "\n",
    "#first layer:\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train_rnn.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#second layer\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#third layer\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#fourth layer\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# YOUR CODE HERE!\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 1, 30)             3840      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 1, 30)             7320      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 1, 30)             7320      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 25,831\n",
      "Trainable params: 25,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "# YOUR CODE HERE!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 282 samples, validate on 95 samples\n",
      "Epoch 1/250\n",
      "282/282 [==============================] - 6s 22ms/sample - loss: 0.1621 - val_loss: 0.1457\n",
      "Epoch 2/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.1519 - val_loss: 0.1354\n",
      "Epoch 3/250\n",
      "282/282 [==============================] - 0s 166us/sample - loss: 0.1405 - val_loss: 0.1247\n",
      "Epoch 4/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.1299 - val_loss: 0.1134\n",
      "Epoch 5/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.1168 - val_loss: 0.1013\n",
      "Epoch 6/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.1038 - val_loss: 0.0886\n",
      "Epoch 7/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0919 - val_loss: 0.0751\n",
      "Epoch 8/250\n",
      "282/282 [==============================] - 0s 169us/sample - loss: 0.0796 - val_loss: 0.0615\n",
      "Epoch 9/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0636 - val_loss: 0.0490\n",
      "Epoch 10/250\n",
      "282/282 [==============================] - 0s 181us/sample - loss: 0.0501 - val_loss: 0.0388\n",
      "Epoch 11/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0416 - val_loss: 0.0336\n",
      "Epoch 12/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0406 - val_loss: 0.0332\n",
      "Epoch 13/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0404 - val_loss: 0.0329\n",
      "Epoch 14/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0440 - val_loss: 0.0316\n",
      "Epoch 15/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0374 - val_loss: 0.0307\n",
      "Epoch 16/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0346 - val_loss: 0.0304\n",
      "Epoch 17/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0375 - val_loss: 0.0297\n",
      "Epoch 18/250\n",
      "282/282 [==============================] - 0s 181us/sample - loss: 0.0381 - val_loss: 0.0284\n",
      "Epoch 19/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0339 - val_loss: 0.0267\n",
      "Epoch 20/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0360 - val_loss: 0.0250\n",
      "Epoch 21/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0330 - val_loss: 0.0233\n",
      "Epoch 22/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0286 - val_loss: 0.0218\n",
      "Epoch 23/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0309 - val_loss: 0.0203\n",
      "Epoch 24/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0270 - val_loss: 0.0186\n",
      "Epoch 25/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0273 - val_loss: 0.0170\n",
      "Epoch 26/250\n",
      "282/282 [==============================] - 0s 181us/sample - loss: 0.0268 - val_loss: 0.0164\n",
      "Epoch 27/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0260 - val_loss: 0.0150\n",
      "Epoch 28/250\n",
      "282/282 [==============================] - 0s 181us/sample - loss: 0.0239 - val_loss: 0.0133\n",
      "Epoch 29/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0211 - val_loss: 0.0122\n",
      "Epoch 30/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0221 - val_loss: 0.0105\n",
      "Epoch 31/250\n",
      "282/282 [==============================] - 0s 185us/sample - loss: 0.0195 - val_loss: 0.0093\n",
      "Epoch 32/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0192 - val_loss: 0.0088\n",
      "Epoch 33/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0183 - val_loss: 0.0076\n",
      "Epoch 34/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0177 - val_loss: 0.0068\n",
      "Epoch 35/250\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0187 - val_loss: 0.0056\n",
      "Epoch 36/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0185 - val_loss: 0.0058\n",
      "Epoch 37/250\n",
      "282/282 [==============================] - 0s 181us/sample - loss: 0.0139 - val_loss: 0.0056\n",
      "Epoch 38/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0148 - val_loss: 0.0055\n",
      "Epoch 39/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0162 - val_loss: 0.0053\n",
      "Epoch 40/250\n",
      "282/282 [==============================] - 0s 186us/sample - loss: 0.0141 - val_loss: 0.0047\n",
      "Epoch 41/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0147 - val_loss: 0.0045\n",
      "Epoch 42/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0149 - val_loss: 0.0043\n",
      "Epoch 43/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0146 - val_loss: 0.0034\n",
      "Epoch 44/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0138 - val_loss: 0.0030\n",
      "Epoch 45/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0138 - val_loss: 0.0033\n",
      "Epoch 46/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0117 - val_loss: 0.0028\n",
      "Epoch 47/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0166 - val_loss: 0.0028\n",
      "Epoch 48/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0122 - val_loss: 0.0033\n",
      "Epoch 49/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0103 - val_loss: 0.0031\n",
      "Epoch 50/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0127 - val_loss: 0.0027\n",
      "Epoch 51/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0120 - val_loss: 0.0024\n",
      "Epoch 52/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0132 - val_loss: 0.0028\n",
      "Epoch 53/250\n",
      "282/282 [==============================] - 0s 183us/sample - loss: 0.0114 - val_loss: 0.0032\n",
      "Epoch 54/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0113 - val_loss: 0.0031\n",
      "Epoch 55/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0150 - val_loss: 0.0032\n",
      "Epoch 56/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0112 - val_loss: 0.0029\n",
      "Epoch 57/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0118 - val_loss: 0.0028\n",
      "Epoch 58/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0106 - val_loss: 0.0026\n",
      "Epoch 59/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0100 - val_loss: 0.0027\n",
      "Epoch 60/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0135 - val_loss: 0.0037\n",
      "Epoch 61/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0109 - val_loss: 0.0030\n",
      "Epoch 62/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0097 - val_loss: 0.0023\n",
      "Epoch 63/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0089 - val_loss: 0.0019\n",
      "Epoch 64/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0101 - val_loss: 0.0019\n",
      "Epoch 65/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0091 - val_loss: 0.0019\n",
      "Epoch 66/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0103 - val_loss: 0.0019\n",
      "Epoch 67/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0109 - val_loss: 0.0017\n",
      "Epoch 68/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0107 - val_loss: 0.0015\n",
      "Epoch 69/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0121 - val_loss: 0.0022\n",
      "Epoch 70/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0099 - val_loss: 0.0023\n",
      "Epoch 71/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0087 - val_loss: 0.0018\n",
      "Epoch 72/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0100 - val_loss: 0.0016\n",
      "Epoch 73/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0097 - val_loss: 0.0014\n",
      "Epoch 74/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0078 - val_loss: 0.0013\n",
      "Epoch 75/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0089 - val_loss: 0.0016\n",
      "Epoch 76/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0089 - val_loss: 0.0017\n",
      "Epoch 77/250\n",
      "282/282 [==============================] - 0s 179us/sample - loss: 0.0099 - val_loss: 0.0015\n",
      "Epoch 78/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0079 - val_loss: 0.0014\n",
      "Epoch 79/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0101 - val_loss: 0.0015\n",
      "Epoch 80/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0105 - val_loss: 0.0015\n",
      "Epoch 81/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0112 - val_loss: 0.0015\n",
      "Epoch 82/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0063 - val_loss: 0.0015\n",
      "Epoch 83/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0098 - val_loss: 0.0018\n",
      "Epoch 84/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0096 - val_loss: 0.0018\n",
      "Epoch 85/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0102 - val_loss: 0.0017\n",
      "Epoch 86/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0100 - val_loss: 0.0018\n",
      "Epoch 87/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0100 - val_loss: 0.0020\n",
      "Epoch 88/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0108 - val_loss: 0.0025\n",
      "Epoch 89/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0089 - val_loss: 0.0023\n",
      "Epoch 90/250\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 91/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0081 - val_loss: 0.0016\n",
      "Epoch 92/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0082 - val_loss: 0.0016\n",
      "Epoch 93/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0084 - val_loss: 0.0016\n",
      "Epoch 94/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0080 - val_loss: 0.0015\n",
      "Epoch 95/250\n",
      "282/282 [==============================] - 0s 179us/sample - loss: 0.0090 - val_loss: 0.0015\n",
      "Epoch 96/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0096 - val_loss: 0.0015\n",
      "Epoch 97/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0083 - val_loss: 0.0015\n",
      "Epoch 98/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0084 - val_loss: 0.0015\n",
      "Epoch 99/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0081 - val_loss: 0.0014\n",
      "Epoch 100/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0092 - val_loss: 0.0012\n",
      "Epoch 101/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0068 - val_loss: 0.0012\n",
      "Epoch 102/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0106 - val_loss: 0.0012\n",
      "Epoch 103/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0088 - val_loss: 0.0019\n",
      "Epoch 104/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0082 - val_loss: 0.0020\n",
      "Epoch 105/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 106/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0086 - val_loss: 0.0016\n",
      "Epoch 107/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0090 - val_loss: 0.0014\n",
      "Epoch 108/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0095 - val_loss: 0.0013\n",
      "Epoch 109/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 110/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0086 - val_loss: 0.0015\n",
      "Epoch 111/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0105 - val_loss: 0.0018\n",
      "Epoch 112/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0074 - val_loss: 0.0020\n",
      "Epoch 113/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0074 - val_loss: 0.0019\n",
      "Epoch 114/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0083 - val_loss: 0.0018\n",
      "Epoch 115/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0113 - val_loss: 0.0017\n",
      "Epoch 116/250\n",
      "282/282 [==============================] - 0s 180us/sample - loss: 0.0079 - val_loss: 0.0018\n",
      "Epoch 117/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0087 - val_loss: 0.0019\n",
      "Epoch 118/250\n",
      "282/282 [==============================] - 0s 179us/sample - loss: 0.0078 - val_loss: 0.0020\n",
      "Epoch 119/250\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0091 - val_loss: 0.0021\n",
      "Epoch 120/250\n",
      "282/282 [==============================] - 0s 180us/sample - loss: 0.0087 - val_loss: 0.0017\n",
      "Epoch 121/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0086 - val_loss: 0.0015\n",
      "Epoch 122/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0080 - val_loss: 0.0014\n",
      "Epoch 123/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0069 - val_loss: 0.0016\n",
      "Epoch 124/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0073 - val_loss: 0.0019\n",
      "Epoch 125/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0085 - val_loss: 0.0018\n",
      "Epoch 126/250\n",
      "282/282 [==============================] - 0s 191us/sample - loss: 0.0088 - val_loss: 0.0017\n",
      "Epoch 127/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0066 - val_loss: 0.0017\n",
      "Epoch 128/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0071 - val_loss: 0.0015\n",
      "Epoch 129/250\n",
      "282/282 [==============================] - 0s 179us/sample - loss: 0.0085 - val_loss: 0.0015\n",
      "Epoch 130/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0079 - val_loss: 0.0016\n",
      "Epoch 131/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0076 - val_loss: 0.0017\n",
      "Epoch 132/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0073 - val_loss: 0.0015\n",
      "Epoch 133/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0077 - val_loss: 0.0014\n",
      "Epoch 134/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0077 - val_loss: 0.0014\n",
      "Epoch 135/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0088 - val_loss: 0.0016\n",
      "Epoch 136/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0089 - val_loss: 0.0016\n",
      "Epoch 137/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0076 - val_loss: 0.0017\n",
      "Epoch 138/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0080 - val_loss: 0.0017\n",
      "Epoch 139/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 140/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0082 - val_loss: 0.0016\n",
      "Epoch 141/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 142/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0092 - val_loss: 0.0010\n",
      "Epoch 143/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0085 - val_loss: 0.0010\n",
      "Epoch 144/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0070 - val_loss: 0.0012\n",
      "Epoch 145/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0079 - val_loss: 0.0014\n",
      "Epoch 146/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0082 - val_loss: 0.0015\n",
      "Epoch 147/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 148/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0090 - val_loss: 0.0021\n",
      "Epoch 149/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0079 - val_loss: 0.0023\n",
      "Epoch 150/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0074 - val_loss: 0.0020\n",
      "Epoch 151/250\n",
      "282/282 [==============================] - 0s 168us/sample - loss: 0.0070 - val_loss: 0.0016\n",
      "Epoch 152/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0061 - val_loss: 0.0012\n",
      "Epoch 153/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0064 - val_loss: 0.0011\n",
      "Epoch 154/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0077 - val_loss: 0.0014\n",
      "Epoch 155/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0075 - val_loss: 0.0013\n",
      "Epoch 156/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0074 - val_loss: 0.0012\n",
      "Epoch 157/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0085 - val_loss: 0.0014\n",
      "Epoch 158/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0071 - val_loss: 0.0018\n",
      "Epoch 159/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0080 - val_loss: 0.0021\n",
      "Epoch 160/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 161/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0081 - val_loss: 0.0016\n",
      "Epoch 162/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 163/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0074 - val_loss: 0.0015\n",
      "Epoch 164/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0081 - val_loss: 0.0016\n",
      "Epoch 165/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0081 - val_loss: 0.0014\n",
      "Epoch 166/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 167/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 168/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0077 - val_loss: 0.0012\n",
      "Epoch 169/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 170/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 171/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 172/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0070 - val_loss: 0.0016\n",
      "Epoch 173/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0073 - val_loss: 0.0014\n",
      "Epoch 174/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0076 - val_loss: 0.0015\n",
      "Epoch 175/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0084 - val_loss: 0.0017\n",
      "Epoch 176/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0060 - val_loss: 0.0018\n",
      "Epoch 177/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0070 - val_loss: 0.0016\n",
      "Epoch 178/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 179/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0075 - val_loss: 0.0013\n",
      "Epoch 180/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 181/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0062 - val_loss: 0.0013\n",
      "Epoch 182/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 183/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 184/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 185/250\n",
      "282/282 [==============================] - 0s 182us/sample - loss: 0.0080 - val_loss: 0.0014\n",
      "Epoch 186/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0079 - val_loss: 0.0014\n",
      "Epoch 187/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0099 - val_loss: 0.0015\n",
      "Epoch 188/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0078 - val_loss: 0.0015\n",
      "Epoch 189/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0069 - val_loss: 0.0015\n",
      "Epoch 190/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0082 - val_loss: 0.0017\n",
      "Epoch 191/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 192/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0074 - val_loss: 0.0014\n",
      "Epoch 193/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0074 - val_loss: 0.0013\n",
      "Epoch 194/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 195/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0078 - val_loss: 0.0016\n",
      "Epoch 196/250\n",
      "282/282 [==============================] - 0s 182us/sample - loss: 0.0068 - val_loss: 0.0019\n",
      "Epoch 197/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0072 - val_loss: 0.0018\n",
      "Epoch 198/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0075 - val_loss: 0.0017\n",
      "Epoch 199/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 200/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0074 - val_loss: 0.0017\n",
      "Epoch 201/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0078 - val_loss: 0.0018\n",
      "Epoch 202/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0072 - val_loss: 0.0016\n",
      "Epoch 203/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0074 - val_loss: 0.0015\n",
      "Epoch 204/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 205/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0067 - val_loss: 0.0013\n",
      "Epoch 206/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0071 - val_loss: 0.0012\n",
      "Epoch 207/250\n",
      "282/282 [==============================] - 0s 209us/sample - loss: 0.0073 - val_loss: 0.0012\n",
      "Epoch 208/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0080 - val_loss: 0.0011\n",
      "Epoch 209/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0067 - val_loss: 0.0012\n",
      "Epoch 210/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0078 - val_loss: 0.0014\n",
      "Epoch 211/250\n",
      "282/282 [==============================] - 0s 179us/sample - loss: 0.0059 - val_loss: 0.0014\n",
      "Epoch 212/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0070 - val_loss: 0.0015\n",
      "Epoch 213/250\n",
      "282/282 [==============================] - 0s 180us/sample - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 214/250\n",
      "282/282 [==============================] - 0s 180us/sample - loss: 0.0065 - val_loss: 0.0017\n",
      "Epoch 215/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 216/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0072 - val_loss: 0.0016\n",
      "Epoch 217/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0062 - val_loss: 0.0013\n",
      "Epoch 218/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0064 - val_loss: 0.0011\n",
      "Epoch 219/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0063 - val_loss: 0.0010\n",
      "Epoch 220/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0065 - val_loss: 0.0012\n",
      "Epoch 221/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0079 - val_loss: 0.0014\n",
      "Epoch 222/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 223/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0080 - val_loss: 0.0018\n",
      "Epoch 224/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0076 - val_loss: 0.0018\n",
      "Epoch 225/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0080 - val_loss: 0.0017\n",
      "Epoch 226/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0060 - val_loss: 0.0015\n",
      "Epoch 227/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0065 - val_loss: 0.0014\n",
      "Epoch 228/250\n",
      "282/282 [==============================] - 0s 187us/sample - loss: 0.0067 - val_loss: 0.0014\n",
      "Epoch 229/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 230/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0078 - val_loss: 0.0014\n",
      "Epoch 231/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0065 - val_loss: 0.0013\n",
      "Epoch 232/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0052 - val_loss: 0.0013\n",
      "Epoch 233/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0059 - val_loss: 0.0012\n",
      "Epoch 234/250\n",
      "282/282 [==============================] - 0s 175us/sample - loss: 0.0067 - val_loss: 0.0013\n",
      "Epoch 235/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0060 - val_loss: 0.0012\n",
      "Epoch 236/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0063 - val_loss: 0.0011\n",
      "Epoch 237/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0068 - val_loss: 0.0011\n",
      "Epoch 238/250\n",
      "282/282 [==============================] - 0s 172us/sample - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 239/250\n",
      "282/282 [==============================] - 0s 184us/sample - loss: 0.0072 - val_loss: 0.0015\n",
      "Epoch 240/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 241/250\n",
      "282/282 [==============================] - 0s 177us/sample - loss: 0.0068 - val_loss: 0.0013\n",
      "Epoch 242/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0055 - val_loss: 0.0013\n",
      "Epoch 243/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0076 - val_loss: 0.0013\n",
      "Epoch 244/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0056 - val_loss: 0.0014\n",
      "Epoch 245/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0069 - val_loss: 0.0012\n",
      "Epoch 246/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0082 - val_loss: 0.0013\n",
      "Epoch 247/250\n",
      "282/282 [==============================] - 0s 173us/sample - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 248/250\n",
      "282/282 [==============================] - 0s 170us/sample - loss: 0.0075 - val_loss: 0.0016\n",
      "Epoch 249/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0071 - val_loss: 0.0016\n",
      "Epoch 250/250\n",
      "282/282 [==============================] - 0s 174us/sample - loss: 0.0061 - val_loss: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2eab04b62c8>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "# YOUR CODE HERE!\n",
    "batch_size = 60\n",
    "epochs = 250\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 86us/sample - loss: 0.0034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.003376810142964673"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# YOUR CODE HERE!\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "# YOUR CODE HERE!\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3670.919922</td>\n",
       "      <td>4052.100342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3670.919922</td>\n",
       "      <td>4092.723389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3912.570068</td>\n",
       "      <td>4092.723389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3924.239990</td>\n",
       "      <td>4278.056641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3974.050049</td>\n",
       "      <td>4287.107910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Real    Predicted\n",
       "0  3670.919922  4052.100342\n",
       "1  3670.919922  4092.723389\n",
       "2  3912.570068  4092.723389\n",
       "3  3924.239990  4278.056641\n",
       "4  3974.050049  4287.107910"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "btc_closing = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "})\n",
    "btc_closing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2eab2910548>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5jU1dXA8e/Z2d4bsGxjadI7IoiKxoYNu2JiSzRqEqOpRmN6Yl5Ntddo7L2XoNiwUZTekaUsW2B77zNz3z/ub3ZnGyzsLls8n+fhmdn7K3NngTlz27lijEEppZRqT0BvV0AppVTfpUFCKaVUhzRIKKWU6pAGCaWUUh3SIKGUUqpDGiSUUkp1SIOE6nUiskRErnaef0dEFh/ifRaJyBXdW7vuJyLHisi2w/yax4tIThfvcdjr3RERSReRKhFx9XZdBjoNEv2QiOwWkVrnP0mpiLwjImnOsUVOeZWINIpIg9/PDzrnRIvInSKyxynPdH5O7N13BsaYZ4wxpxzoPBH5g4g83era04wxT/Rc7bqHMeYzY8yY3q7HwepL9TbG7DHGRBpjPL1dl4FOg0T/dZYxJhIYCuQD90DTB2Wkc+wZ4G++n40x14lIMPAhMAGYD0QDRwPFwKyuVkpEArt6D6X2R/+NHV4aJPo5Y0wd8DIwvpOXXA6kA+caYzYbY7zGmAJjzJ+NMf9r7wIRMSJyg4jsFJEiEfm7iAQ4x64UkS9E5N8iUgL8wSn/nohscVo674nIML/7nSwiW0WkXETuBcTv2JUi8rnfzxNE5H0RKRGRfBH5tYjMB34NXOy0hNY55/p3WwWIyG9EJEtECkTkSRGJcY5lOO/pCqc1VSQit/q95iwRWSkiFc5r/quD30uLuvr9rkY5z08Xkc0iUikiuSLyC6e8RdeP0zL8hYisd34nL4hIqN/xm0Rkr4jkicjV/q/RTp3iReS/zrmlIvJ6B+eNc35fZSKySUQW+B3rjXovEZH/E5EvnXu9ISLxrf6+rhKRPcBHfmWBB3rfInKmiKx13utSEZncXh1U+zRI9HMiEg5cDCzv5CUnAe8aY6oO8qXOBWYC04Gzge/5HTsK2AkMBm4TkXOwH+LnAYOAz4DnnPomAq8AvwESgR3A3PZeUESigA+Ad4FkYBTwoTHmXeCvwAtOC2lKO5df6fw5ARgBRAL3tjrnGGAMcCLwOxEZ55TfBdxljIkGRgIv7vc307FHgWuNMVHAROCj/Zx7EbZlNxyY7NQdJyD+DPv3NgqYd4DXfAoIx7YUBwP/bn2CiAQBbwGLnXN+DDwjIr6upN6oN9gvMN/D/l27gbtbHZ8HjANObefadt+3iEwHHgOuBRKAh4A3RSSkE/VRaJDoz14XkTKgAjgZ+Hsnr0sA9h7C691hjCkxxuwB7gQu8TuWZ4y5xxjjNsbUYv9D/p8xZosxxo39QJ/qtCZOBzYbY142xjQ699rXwWueCewzxvzTGFNnjKk0xqzoZH2/A/zLGLPTCYi3AAulZVfFH40xtcaYdcA6wBdsGoFRIpJojKkyxnQ2ALfWCIwXkWhjTKkxZvV+zr3bGJNnjCnBfoBPdcovAv5rjNlkjKkB/tjRDURkKHAacJ3zeo3GmE/aOXU2NmjeboxpMMZ8BLxN89/pYa23n6eMMRuNMdXAb4GLpOXA9B+MMdXOv7HOvu/vAw8ZY1YYYzzOmFW98ztQnaBBov86xxgTC4QA1wOfiEhSJ64rxo5jHKxsv+dZ2G977R0DGAbc5TTvy4ASbJdSinNd0/nGZphsfb1PGralcSiSnXr61zkQGOJX5h+carAfnABXAUcAW0XkKxE58xDrcD42KGaJyCciMmc/53ZUlxa/Lzr+XYH9fZUYY0oPUK9kINsY4/Ury8L+/fRGvds7JwsIwrY2D3SP/b3vYcDPff8WnX+PabT896v2Q4NEP+d8O3oV8GC7Tw7kA+BUEYk4yJdK83ueDuT5V6PVudnY7opYvz9hxpil2FZM071ERFrdu/V9RnZw7EDpi/OwHxD+dXZjB/n3yxiz3RhzCbbb4g7g5Q5+X9XYLg4AWgdpY8xXxpiznfu8zqF1W+0FUv1+7uh3Bfb3FS8isQe4Zx6QJs64kiMdyIVeqXd756RjWzRFfmUd/Z3v731nA7e1+rcYbox5rhP1UWiQ6PfEOhuIA7Z04pKnsP9xXhGRsWIHeBPEDgifvp/rfikicWKn2t4IvLCfcx8EbhGRCU4dY0TkQufYO8AEETnP6fq5AeioBfQ2kCQiPxGREBGJEpGjnGP5QEarDzp/zwE/FZHhIhJJ8xiGez/1xqnvpSIyyPmmXeYUtzfVcp3zXqY6A7Z/8LtHsNg1HzFOt1pFB/c4kBeB7zoDzeHA7zo60RizF1gE3O/8XQWJyHHtnLoCG+Bucs45HjgLeL436u3nUhEZ75z/J+DlzkxxPcD7fgS4TkSOcv6vRIjIGc54l+oEDRL911siUoX9T3wbcIUxZtOBLjLG1GMHE7cC7zvXf4lt1u+vv/8NYBWwFvtB/+h+XuM17Dfw50WkAtiI7TPGGFMEXAjcju36Gg180cF9KrHjLWdhuzW2YweiAV5yHotFpL0+88ewAfFTYBdQhx2g7Yz5wCbn93sXsNCZRda6fl9jP8w+cOr2eatTLgN2O7+D64BLO/n6/q+xCDuA+zGQCSxzDtV3cMll2G/gW4EC4Cft3LMBWID9OykC7gcuN8Zs7cV6g/37ehz7dx2K/QLRWe2+b2PMSuy4xL1AqVOXKw/ivt94opsOqQMREQOMNsZk9nZdvumcGVgbgZDOtIr6igPVW0SWAE8bY/5zuOum9k9bEkr1cSJyrtMNFIdtob3VHwJEf623akmDhFJ937VAIXamlwf4Qe9Wp9P6a72VH+1uUkop1SFtSSillOpQv02UlZiYaDIyMnq7Gkop1a+sWrWqyBgzqLPn99sgkZGRwcqVK3u7Gkop1a+ISNaBz2qm3U1KKaU6pEFCKaVUhzRIKKWU6lC/HZNoT2NjIzk5OdTVtcmgoA5CaGgoqampBAUF9XZVlFK9bEAFiZycHKKiosjIyMAmF1UHyxhDcXExOTk5DB8+vLero5TqZQOqu6muro6EhAQNEF0gIiQkJGhrTCkFDLAgAWiA6Ab6O1RK+Qy4IKGUUq29t2kfBRXaOj4UGiS6mcvlYurUqUycOJGzzjqLsrKyA1/UgYyMDIqKig58olKqQ3WNHq57ehXPrNjT21XplzRIdLOwsDDWrl3Lxo0biY+P57777uvtKin1jVZc3YAxUFHX2NtV6Zc0SPSgOXPmkJub2/Tz3//+d4488kgmT57M73//+6byc845hxkzZjBhwgQefvjh3qiqUgNWSVUDAFV1upXFoRhQU2D9/fGtTWzOq+jWe45Pjub3Z03o1Lkej4cPP/yQq666CoDFixezfft2vvzyS4wxLFiwgE8//ZTjjjuOxx57jPj4eGpraznyyCM5//zzSUhI6Na6K/VNVVxtd0ytqtcgcSi0JdHNamtrmTp1KgkJCZSUlHDyyScDNkgsXryYadOmMX36dLZu3cr27dsBuPvuu5kyZQqzZ88mOzu7qVwp1XUl1U5LQoPEIRmwLYnOfuPvbr4xifLycs4880zuu+8+brjhBowx3HLLLVx77bUtzl+yZAkffPABy5YtIzw8nOOPP17XKCjVjXxBolK7mw6JtiR6SExMDHfffTf/+Mc/aGxs5NRTT+Wxxx6jqqoKgNzcXAoKCigvLycuLo7w8HC2bt3K8uXLe7nmSg0sxYe5JdHg9h6W1zlcNEj0oGnTpjFlyhSef/55TjnlFL797W8zZ84cJk2axAUXXEBlZSXz58/H7XYzefJkfvvb3zJ79uzerrZSA8rhHLjOLqlhyh8Xs2RbQY+/1uEyYLubeouvpeDz1ltvNT2/8cYbufHGG9tcs2jRonbvtXv37m6tm1LfRIezJfHq6lxqGz18vr2I48cM7vHXOxy0JaGUGtD8Zzd5vabHXscYw+tr7ZT39TnlPfY6h5sGCaXUgOYbuAaobui51sT6nHJ2FVWTGBnMxrxyPD0YkA4nDRJKqQGtpKqBsCAX0Nzl9N6mfWzM7d5v+6+vzSXYFcD1J4yipsHDjsKqA1/UD2iQUEoNWPVuD5X1boYlhAPNg9e/eX0j/1y8rdtex+3x8ta6PE4cN5hjRicCsC770PO29SUaJJRSA1Zptc3XlB5vg0RlvRtjDCXVDWzILceY7ukS2pBbTlFVA2dMHsqIxEgiQwIHzLiEBgml1IDlG7T2b0lU1LrxeA1FVQ3sLe+ehas5pbUAjB4cRUCAMDElmvU52pJQ7fBPFX7hhRdSU1NzyPdasmQJZ555JgBvvvkmt99+e4fnlpWVcf/99x/0a/zhD3/gH//4xyHXUam+zDdonZ4QAdgxCV/gALrtgzyvzAaJ5NhQACanxrJlb+WAWFinQaKb+acKDw4O5sEHH2xx3BiD13vw/3AWLFjAzTff3OHxQw0SSg1kviAxLL65JVFa0zzbqbu6hPLKaokKDSQqNAiAyakxNHi8bNtX2S33700HDBIi8piIFIjIRr+yv4vIVhFZLyKviUis37FbRCRTRLaJyKl+5TNEZINz7G5x9sgUkRARecEpXyEiGd37FnvPscceS2ZmJrt372bcuHH88Ic/ZPr06WRnZ7N48WLmzJnD9OnTufDCC5sW4b377ruMHTuWY445hldffbXpXo8//jjXX389APn5+Zx77rlMmTKFKVOmsHTpUm6++WZ27NjB1KlT+eUvfwl0nJr8tttuY8yYMZx00kls29Z9g3dK9TXFzmprX3dTZb27qSwkMKDbgkRuWR0psWFNP09JtR+JG7p5BlVv6MyK68eBe4En/creB24xxrhF5A7gFuBXIjIeWAhMAJKBD0TkCGOMB3gAuAZYDvwPmA8sAq4CSo0xo0RkIXAHcHGX39mim2Hfhi7fpoWkSXBax10+/txuN4sWLWL+/PkAbNu2jf/+97/cf//9FBUV8Ze//IUPPviAiIgI7rjjDv71r39x00038f3vf5+PPvqIUaNGcfHF7f8abrjhBubNm8drr72Gx+OhqqqK22+/nY0bN7J27Vqg49TkERERPP/886xZswa328306dOZMWNG9/x+lOpjSqobcAUIyc4HuH9LYvaIBNbsKcUY0+V93fPKalsEiZTYMIJdAWQVV3fpvn3BAVsSxphPgZJWZYuNMb5VKcuBVOf52cDzxph6Y8wuIBOYJSJDgWhjzDJjpxM8CZzjd80TzvOXgROlq39jvciXKnzmzJmkp6c37ScxbNiwprxMy5cvZ/PmzcydO5epU6fyxBNPkJWVxdatWxk+fDijR49GRLj00kvbfY2PPvqIH/zgB4AdA4mJiWlzTkepyT/77DPOPfdcwsPDiY6OZsGCBT30m1Cq9xVX1xMXHkSQK4DwYBeVdY1NaTqOHzOIijo3WcUdjxtmFlTx2pqcA75OblltUyACCAgQUuLCmga0+7PuyN30PeAF53kKNmj45Dhljc7z1uW+a7IBnJZJOZAAtNncWUSuwbZGSE9P33+tOvmNv7v5xiRai4iIaHpujOHkk0/mueeea3HO2rVru/yNxv812ktNfuedd3bbayjV1xVXNRAfEQxAZEhg02K6sCAXs4bHA7A+t5yMxIh2r39q2W6eXrGHsyYnE+hq/zt1Vb2b8trGFkECIDUujOzSQ5+40ld0aeBaRG4F3MAzvqJ2TjP7Kd/fNW0LjXnYGDPTGDNz0KBBB1vdPmP27Nl88cUXZGZmAlBTU8PXX3/N2LFj2bVrFzt27ABoE0R8TjzxRB544AHA7oBXUVFBVFQUlZXNg2QdpSY/7rjjeO2116itraWysrJFAkKlBpqS6gYSIkIAiAwNpLLeTUmNDRxHDImy4xL7WfRWVN2Ax2vIr6zv8Jy9rWY2+aTFh5Nd8g0OEiJyBXAm8B3TvCIlB0jzOy0VyHPKU9spb3GNiAQCMbTq3hpoBg0axOOPP84ll1zC5MmTmT17Nlu3biU0NJSHH36YM844g2OOOYZhw4a1e/1dd93Fxx9/zKRJk5gxYwabNm0iISGBuXPnMnHiRH75y192mJp8+vTpXHzxxUydOpXzzz+fY4899jC/e6UOn5LqBuIjbUsiKiSQqjq3LYsIJsgVwOghkWwv6Dh9RnGVDQ6+Ka7tyXWOpbRqSaTFhVNa09jvd8Q7pO4mEZkP/AqYZ4zxD5VvAs+KyL+wA9ejgS+NMR4RqRSR2cAK4HLgHr9rrgCWARcAH5nuWgbZC1qnCgfIyMhg48aNLcq+9a1v8dVXX7U5d/78+WzdurVN+ZVXXsmVV14JwJAhQ3jjjTfanPPss8+2+Lmj1OS33nort956637fh1IDQXF1Awm+7qZQ293U6PE2dUENjgqloLLjBXW+KbT7CxJ5Zfb69rqbAHJKaxibFM0TS3czLT2Wyamxbe7Rl3VmCuxz2A/wMSKSIyJXYWc7RQHvi8haEXkQwBizCXgR2Ay8C/zImdkE8APgP9jB7B3YmU0AjwIJIpIJ/AzoeDGAUkp1UqPHS3ltY8sxCacl4QscCRHBTVNi2+M7lrvfIFGLK0AYHBXSojzNWZuRXVJLZV0jf3hrEw99srNL76k3HLAlYYy5pJ3iR/dz/m3Abe2UrwQmtlNeB1x4oHoopdTBKHK6ihIjnTGJkCCq6u0U2DhfkIgMobiqod1psB6voaSmMy2JWpKiQ9sMbKc5LYnskhoigl0YA6v3lHbPmzuMBtzOdN0x5/mbrh/39inVxDe11ZfcLyo0kKKqeurdzd1NiZHBNHi8VNa7iXZWS/uU1jTg+6/g61JqT26rNRI+8RHBhAW5yCmtpc5tO1T2ltext7yWoTFtz++rBlRajtDQUIqLi/VDrguMMRQXFxMaGnrgk5Xqw/Y4QcK32joyJJB6J5dSfFNLwj621+XkKwuQA7QkymvbzGwCEBHS4u002LV7ygh2Whqrs/pX4r8B1ZJITU0lJyeHwsLC3q5KvxYaGkpqauqBT1SqD8sqqSYwQJq+5UeGNn/cNbckbFdUUVU9w1utlfAlAhw9OKrDMQmP17C3rI7kye23DNLi7DTY0poGTp4whA8257N6TylnTB7atTd3GA2oIBEUFMTw4cN7uxpKqT4gq7iGlLiwprGCyJDmj7vmgWsbJHxTXf35WhITU2LYll9JRV1jmy6pwsp63F7TZmaTT2pcGJ98XYjbazhyWBwFFXX9blxiQHU3KaWUz56SmqbxCLBjEj5xfmMSAEXtdjfZwDE51aa92dvOuERume3Sam9MAuwMJ7ez1/WUtFimp8exKbeCeren3fP7Ig0SSqkBaXdRddN4BLQMEr6WhC9YtDsmUd2ACIxPjgbaH5dYtGEfrgBhgnNOa6lx9vWDXML45GimpcfR4PGyMbfiEN/V4adBQik14JTVNFBR52ZYfPM4Q2RIECkUEhVQ39RtFOQKIDY8qMVGRD7F1Q3EhweT5nzQtx6XqK5388LKbE6bmMTg6PYneqTF2xbG+KHRhAS6mD7MLqRb04+6nDRIKKUGnKbpr34ticjgAN4M+Q0/DXmTgIDmafIJEcFNayr8FVfVkxAZzKCoEAIDpE1L4rU1uVTWufnu3IwO6+FrSUxJs8FhcFQoQ2NC2ZzXf1oSA2rgWimlALJKWk5/BYh1F5IglYwIbDn7MTEypIMxCZsc0BUgJMWEtggSxhgeX7qbSSkxTE+P67AeMWFB3HH+JI4emdhUNjg6lKLqjld59zXaklBKDTh7nM1+WgxcV+0GYLC03C0uMTKk/dlNfskBk2PDyCtvHrheuqOYzIIqrjg644CLdy8+Mr0pRQfYlktJO91bfZUGCaXUgJNVXMPgqBDCg5s7S8Iqbd6kBNNyPCAhMrhpIyJ/xVX1JDoD2ymxYS1aEi98lU10aCBndrTeweOGJXdAya42h+IPkC+qr9EgoZQacLJKalp0NQEElth9WmI9xS3KEyJCKKtppNHjbSprcHupqHOT4Cy2S44NZV95HZV1jZTXNvLepn2cPTWF0CBX+xX44k5Y8lf47B9tDvmCUn/JDKFBQik14OwpriE9vtVuc8XbAQjx1kK9k9K/poSkUPutvsSvNeF77kvbMX/CUDzGcNcH23l7fR71bi8XzOggK0H+JlhyO7hCYONrza/lSIgIpsHtpbqhf6yV0CChlBpQ6ho97Kuoa9OSoCgTApwV01X59vG5hZyw8RZ72G9cwvfct55iUmoMF89M4/Glu3n4050cMSSyaZFdCx43vHYdhMXChY9DYzVsfr3FKfH7WeXdF2mQUEoNKJ9tLwJg9ODI5sLGWijPhpQZ9ueqAjAG8jczaN+nDKGkxThBc0uieY+IX546hvBgF1nFNVw4I639Aeu8NbBvPZz8JxhzGiSMhjVPtzilKalgP5nhpEFCKTVgeLyGv7+3leGJEZw0fkjzgeIdgIGMufbnqn1QUwwNlQiGs11ftFhQ53vua0mADRi/Pn0c0aGBnDMtpf0K5K2xj8OPAxGYdinsWWZbMb77OPcs6SeD1xoklFIDxqurc/g6v4pfnjqGIP9NgJzxCDKOsY9VBVC6GwDjCuY81+cUV/oFiaq2LQmAhbPSWfu7UxjUahe6JnvXQngiRDtBZMpCQGDjK02n+DLQtrfKuy/SIKGUGhDqGj38+/2vmZIWy2kTk1oeLHa+yaceCQGBULmvKUgw/QrGBmQjBc370BdVNRDkEqJ9+Z5yVsHbPwWvt8Vq7Tby1kLyVNuKAIhKgsHjIKd5P/umzLNOd9Oe4hqynHUdfZEGCaXUgPDo57vIK6/j5vlj244XFGXab/chURAx2GlJ2DUMcsxPaSSQUXvfbjp9Z2EVg6NCm++z6VVY+RiUZXVcgcZaKNwKQ6e2LE+ZDnmr8W1zFxbsIjzY1dTd9IuX13HzKxu69uZ7kAYJpVS/t6+8jvs+zmT+hCTmjExoe0LxdkgYZZ9HDbFjEqW7ITIJYlLYGDSJYRWrATto/fG2Ak6d4Nca8bU69u3nw3zfRjAe25Lwlzzdjn/4AkzWMiaFFTe1JLbnV1LYiZlOFXWNvLtx72FfX6FBQinV793x7lbcXsOtZ4xre9AY25JIHG1/jkyyU2BLdkNcBgC10cOJb8gjt7SGN9bm0ugxXHSk3zqIzgSJvWvtY5uWhDOjKncVNNTA0+fzG++DFFc3UFrdQGlNI2U1jQd8j3e+v53rnl7NB1sKDnhud9IgoZTq17bsreC1Nblcc+yIFjmSmpRlQX25HRsAiBwMlfn2g98JEuMnTCFaanjg3VW88FU2k1NjGJvk7BFhTOeCRN5aCE+AmFaL7IZMsAvrclfD9vegsZoJjRsIqMhhZ5Edi6iobdxvC6G63s1LK7MB+L//bWmxOrynaZBQSvVry3bYNBuXzxnW/gm5q+xjykz7GJUE1YVQkdsUJGKTbStj3fq1bN1XyYUz05qvrymGhiqQgAO3JIb6DVr7uIJg6BRbj42vQkg0ARhmVn7ELidINHi81DW2/OB/b9M+rn5iJRV1jby6JpfKejfXnzCKnUXVPLN8P2Mj3UyDhFKqX1ufU0ZSdGiHG/+QswoCQ+03erAtCYz9Ez/cljnBYmxIMSGBASyYktx8va8VkX40VORATUnb12ishYItbccjfFJm2JbG9sUwZSG5ERM4yf0JOwubU3aU1bZcN/HRlgI+2JLP959YyRNOWvKfn3IEc0clcOeH26msO3AXVXfQIKGU6tfW55S3nyLDJ3eV/SbvclJyRPoNSDvBgVjbCrl2cgB/OWciMWFBzef4gsS4s+xje62JbYucQevp7dchZQa4a8FdBxPOY3fKGYyVPZTtWtN0Snltyw/9fRV1RIUEsmJXSYu05D8/ZQxlNY28vX5vx++5G2mQUEr1WxV1jewsqu44SHgabTeQr6sJINJvJbYvSIREQsRgRgUWtuxqgqapsow9wz7uW9/yeHUxLLrJBqIjTm2/HilO8IhKhrSjKM44C7cJYOS+/xEebDPJlrcavM6vqOOoEfH89dxJHDs6sSkt+bS0WEYOiuCVVTntv1Y30yChlOq3NubYDYQmp8a2f0LBZvvtPcXvG36UEyQCQ9sGDF+rwZ9vqmxsmv2Qb92SWHQT1JbBOQ80t1Zaix9h7z/9MggIICohiXVmJOO9mUxx6l7WqiVRUFnP4OhQvn1UOk9ddVRTWnIR4fwZqazMKj0si/A0SCil+q11TpCYlNJBSyJnpX1M9WtJRAy2j3EZLQeZOwwSWc0tjqRJLYPE9vdh48sw71fNYx7tEYHrV8K8mwGbvynHDCJFCpmaboOEf3dTvdtDSXUDSR2Ms5w7LQUReGV1bsev2U00SCil+q0NuWWkx4cT55eIr4XcVXZaaqzfzKegUAiNbf7g94nLgPIc20Xlz2+qLEMnQ+E228XkaYT3fm0X6c298cCVdQVBgP3IjY8IJtckkiQlTE2NAuw0WJ9CJ4/UkOj2c0QNjQlj7shEXl2dg9fbs4vrNEgopfqtddnlTDrQoHXKzLbTUo/+MUy/vGVZXAYYL5TtaS5zN9jA4QsS4xbY3E8vfAdWPAhFX8PJf4bADoJUBxIiQsgzCQSLh2lxjQQILRbU5VfY/bQ7nLEFnDc9hZzSWtbllB3Uax8sDRJKqX6puKqe3LJapnQUJAq22m/9/l1NPsf9onkg2scXCPy7nMqzAdOyJXHugzb99+LfQMaxdt+IgxQW7KLIZbu9BnkLiA4LatHdlF/htCSiOg4SR49MBGBttgYJpZRqY0OubzyinUHr2jJ4/tsQkQjTLuvcDdsLEr6ZTf5dUxPPg1Nug5BoOPWvbVspnVQTZmcrSXk2sW2ChG1JJMV0HCSGRIcwKCqEDc64TE/RIKGU6pcyC+xCtDFJUS0PeL3w6jU2HcdFT0L00M7dMGqoTZ/RIkg4z+NareY++nq4aZdtWRyicWOdge7yHGLCgnBXFUNFHmBbEkEuIS68g9lS2FlOU1JjWJ/by0FCRB4TkQIR2ehXFi8i74vIducxzu/YLSKSKSLbRORUv/IZIrLBOXa3ODl4RSRERF5wyleISEb3vkWl1ECUVSBd8JsAACAASURBVFxDdGhg2w/SJX+1OZLm3w7Dju78DQMCbDDwDxJ7VkBQeMsFeD6uwEOqt88t586CkBgozyE6LIhLC/8Jz38HsC2JFqnKOzApJZYdhVVU1bu7VJf96UxL4nFgfquym4EPjTGjgQ+dnxGR8cBCYIJzzf0i4nKueQC4Bhjt/PHd8yqg1BgzCvg3cMehvhml1DfH7uJqMhIjWn6Qbn4TPv273Tb0yKsP/qbxI2wivvoqyN9sp7ceeVXTrKRuF5MK5TnEhgUxtnFzUzrx/Iq6jruadn8OD82Dwm1MTovBGNjYg62JA75zY8ynQOtkJWcDTzjPnwDO8St/3hhTb4zZBWQCs0RkKBBtjFlmbKrDJ1td47vXy8CJcqDwqZT6xttdXM2whIjmgoq98PoPbAqM0/95aGMFc34ElXnw9k/gwz9CcBQc87Puq3RrMalQlk16YAnxpszmhfK4ya+oa57+akzThkW4G+CtG+0q8hcuZfIg+x28J8clDjU8DjHG7AVwHp3VKaQA2X7n5ThlKc7z1uUtrjHGuIFyoJ1dQ5RSympwe8ktrWV4gl9q8G3v2GytZ99v10IciuHHwQm/hg0vwdfvwjE/gfD47ql0e2LToDyb0W5ne1UM1BRTUFHPYN/Mpg0vwR0ZtpW0/H67FesxP4PiTBI++CkpMaE9Og22a51qbbUXus1+yvd3Tdubi1yD7bIiPT39UOqnlBoAsktr8BpatiQyP4LYdBg0pms3P+bntsupYDMcdV3X7nUgMalQV8aomuZEf7Wle6msdzPEt0Yi6wuoK4MXLwNXMIw5HU76PYTFwvu/44qkqTyTO63HqnioLYl8pwsJ59G3VVIO4J8dKxXIc8pT2ylvcY2IBAIxtO3eAsAY87AxZqYxZuagQYMOsepKqf7Ol7MoI9FpSbgbYNenMOqkQ56S2iQgABY+Cz9cDsHtbGLUnWLsx+WIoo9pNLbrqKzQptpIinG6m0p323QgM75r9+g+9a+2fM71kHgE51c+w57iKspqbKrxmgY3v3tjI49+vqtp5XZXHGqQeBO4wnl+BfCGX/lCZ8bScOwA9ZdOl1SliMx2xhsub3WN714XAB+Zw72Jq1KqX9ldVAP4tSRyvoSGShh5Yve8gAgEhXXPvfbH2cUuvC6flV7bAqoq2Qf4LaQr3Q2JR8BZd8IvMpv3wAhwwbxfkVCdyWkBX/LgJztxe7zc8NwanlyWxZ/f3szs//uQdzfu61IVOzMF9jlgGTBGRHJE5CrgduBkEdkOnOz8jDFmE/AisBl4F/iRMcbj3OoHwH+wg9k7gEVO+aNAgohkAj/DmSmllFIdySquJiokkARfzqbMD226jOHH9W7FDlZMc8fLR167YVF9md0nYnB0qM0PVZYNcb7A0Ooje8K5mMQx/C7qLR76ZDsn/esTPthSwJ/OnsD7Pz2OpOjQpm1PD9UBxySMMZd0cKjdkG2MuQ24rZ3ylcDEdsrrgAsPVA+llPLZVVzDsMTw5umvOz6E1FkQGt27FTtYUUkgLjAelnon4AkIxlOZDzirrcuz7WZGrZMR+gS4kHk3kfTKVdxzZAnXfxXAtfNGcPkce/68MYN4c20ebo+XQNehdRzpimulVL+T5T/9taoQ9q6DUd3U1XQ4BbggOgXjCmGbSaMuOAFTXUREsIvIkEC/Fd8ZHd9j7JkQGMqZEVtZ/duTuXn+2KZDc0cmUlXv7tKqbA0SSql+pdHjJae0lgzf9Nc9y+zjiON7q0pdkzgab/J03ARSHRRHY/k+xg51WkS+3FG+cYj2BIVC+hzYuYT4iOAWiwtnj7DTd5dmFh1y9TRIKKX6ldzSWjxeQ4avJZG/CSRg/5v+9GXnPkjARY8T5BL2uqMIayhhwZRke6x0t532GnWA/FMjjrdTdp2uKp+EyBDGDY3mi8ziQ66eBgmlVL+yq2n6qy9IbIT4kYdnNlJPiByMRCURExbM1qowEqWcM5z9rCndbTdMCnDt9xZNrahdn7Q5NHdkAqv2lFLX6CGntOagq6dBQinVr/hSUAxP9GtJ9NdWhJ+YsECKTTSJUkGib9ZWya79j0f4JE2GsDjYuaTNobmjEmlwe7nx+TV8659tg8iBaJBQSvUbxhheXZ3DUcPjSYwMsYn4SnfBkDYTJ/udmLAgikwMgXigttTma/LfOnV/AgJg+DzY8XFznifHrOHxBLmExZvzOXNSJ9Om++nutBxKKdVjVmaVsru4huu/NdoWFGyxjwOgJREbHky5y9lAqbrQPtZX7H/Q2t+I42Hz63Y3vsFj7Tasb/2EiMBQ3p07m/qJFzE+PYl/Lzy4emmQUEr1Gy+vzCE82MVpE539HfI32McBECSuPmY4JmUqfIENEg12U6VOtSTApiRxBcPT58G8m2DJ7dBQDaGxjNz2Dnh3Qfq/D7pe2t2klOqT7vs4k4sfWoYvS09Ng5t3NuzljElDiQhxvt/mb7LpvGP7f8LPo0clMnfyePtDVUHn1kj4i02D770LwZE2nbgx9uefrIcJ58Gm18Fz8JsTaUtCKdUnvbo6hx2F1azeU8qMYfH8b8M+qurdXDDDL1eob9B6oGxBE+nsulBdaLuaoPNBAuxeGtd+Cuuesy2LWCftx4RzYNOrNqPsQdKWhFKqz8krq2VHoZ3q+uJXOXi9hoc/3cERQyKZNdzZ38GYATOzqUlYnF3zUVUAm9+AwRMgOOLA1/kLCoWZ320OEGADRmAYbHnzoKukQUIp1ed8vt2uEJ6SFsvb6/N4Y10uX+dX8aMTRjWvKC7Ptt+2B1KQCHBBeCJsfRv2bYCjrume+wZHwOiTYMvbB1+l7qmBUkp1n88yixgUFcKvTxtLdYOHW17dwPDECM6cnNx8Up6zUc9AChJgu5wKt0JYPEy+uPvuO/4cqDr4tOEaJJRSfYrXa/gis4hjRyUya3g8GQnh1DV6+eHxI3EF+I09fPWoTVeRPL33KtsTIhLt44wru3cV+ehT7Oyng6RBQinVp2zeW0FJdQPHjE5ERLhu3khmZcRzzrSU5pPy1toUFEddB4EH/8HXp0UOsXtjHHl19943NBrm3njQl2mQUEr1KZ854xHHjLLfqBeOD+XF0yDIfz+EpffYqa8zv9sbVexZc2+ECx6DmJQDn3uwvvWbg75Eg4RSqs8oqW7gyWW7mZgSbXdmA3j/d/D4GXYFMdjHTa/BzCshNKa3qtpzhkyA8Wf3di2aaJBQSvUJHq/hxufXUFzdwO3nTbaF7gbY9j+7O9vyB23Zx/9nZwEd9YPeq+w3iAYJpVSfcO9HmXy2vYg/LpjAxBSnhbD7U6grtyuqVz9h97Je9yzM/mHPdMeoNjRIKPUNklNaQ73b09vVaCOzoIp7P97OginJLDzSbxHYlrdsmonzH7O5jJ7/th3YPe4XvVfZbxgNEkp9A5TXNHLraxs49m8fc9Y9n7Oxk3se1zV6KK1u6NG6GWP4/ZsbCQty8buzxjcvlvN6YOs7dupm2pE2y6m7Dk78PYRE9WidVDMNEkoNcHWNHk6/+zOe/yqbi2akUVbTyDn3fcHf3t1KVf3+E7799IW1nPfA0h6t39vr9/JFZjG/PHWM3SPCZ89ym8No3Fn251Nug+NugimX9Gh9VEua4E+pAW5HYRW5ZbX87YLJXDQzjbKaBv709mbuX7KDF1fmcPfCqRztTDf1t3pPKYs22hW6VfVuIkN65uPivo8zGTc0mm8fNay50BhY8SC4QmxLAiBpov2jDittSSg1wO0usvsaT0iOBuzmNv+6aCpv/GguIYEB3PNRZptrjDHcsWhr0887C6t6pG5V9W625Vcyf0JSy9XUH/zBJqObdxOERPbIa6vO0SCh1AC3u9hmU81IaJlNdEpaLPMnJrF6T2nTYHZFXSMrd5fwxNLdrNhVwmWz7bf7nU5G1u62IaccY2BKmt96hy8fgS/uhJnfg2N/3iOvqzpPg4RSA9yuomoGR4U0b9Tj9cD296FoO7NHJFDv9rIu2w5kX/3ESi54cBl/eGszIxIjuPm0sbgChB091JJYl1MGwJRUZ9vOfRvhvV/D6FPh9H8MnH0i+jEdk1BqgNtVVM3wRKcVkfkBvPcbKNwCAYEcN+MaomU6y3cWMzQmlC93lXDFnGGcPS2FI4ZEERESSHp8ONU5G2HdGphykBskH8C67DKGJYQTFxEMjXXw6vchNBbOud8umFO9ToOEUgPc7qJqTh4/xO53/NwlEJMK5z4MWZ8T8tUDfBEawXtrz+Vd71UAXH3sCNLiw5uuPyIxmCv3/A6y82y6iG7MTLouu4yZGc4mQp/cDgWb4TsvN2dCVb1Ou5uUGsAq6hoprm4gIzECir4GTwOc9EeYcjEsuAeuWUJu9HQuqHyKI1bcwsxhcS0CBMBC91uke3PAeO0+B92koKKOvPI6pqTF2tlM61+EMWfA6JO77TVU12mQUGoA213kN2hd4HzADxrbfELyVPac8ghPuE9mVuMqzp3sfIP3eqEyH3JWcWzeY6z3Drfl+Zu7rW7rcuw4yNS0GJu0ryLXLphTfYoGCaUGsF1OkBieGGFbAQFBED+8xTmzhsezxEwlTBo4K2aXLXzjR/DPI+A/30IChB82/gSPK8R2B3WTddlluAKECckxsGeZLRx2dLfdX3UPDRJKDWC+NRLDEsKhcBskjAJXUItzYsODqUs5mkYJIjrnE6gqgA1O18+5D1F1xUfkmEGUho+A/E3dUi9jDCuzShgzJIrQIBdkfWHTfg8e3y33V91Hg4RSfcTOwiryymo7PL6jsIpXV+cc1D13F1eTHBNqP4gLt8KgMe2e9+jVxxEw/BjIfB/WPgNeN5z0e5iykJi08cSFB5EVmNEtLYk9xTVc/tiXLN9ZwvFjBtnCrGWQPgcC9COpr9G/EaX6gLpGDxc9tJyfvLC2w3OeWLqbn724jg05nUvOB7a7KSMxAhproXR3y/EIP+HBgbhGn2wHt5fdB8PmtggoIwdFssmdClX5UF3U6ddvra7Rw3kPLGXNnjL+fPYEfnHKGNtyKd5ug4Tqc7oUJETkpyKySUQ2ishzIhIqIvEi8r6IbHce4/zOv0VEMkVkm4ic6lc+Q0Q2OMfuFtEVNOqb5aWV2RRV1bNydwnFVfXtnrO3vA6Auz7c3un77i52gkTRdsDA4PaDBACjnFlF1YUwo+W2oCMHRbKiOsn+0IUupw+3FFBUVc9935nOZXMyCAgQHY/o4w45SIhICnADMNMYMxFwAQuBm4EPjTGjgQ+dnxGR8c7xCcB84H4R8a2WeQC4Bhjt/Jl/qPVSqr9p9Hh58JOdJMeE4jXw4daCds8rqLBB4oMt+Z1K9b11XwVlNY0MT4iw4xHQYUsCgMTREJMOYfHNmVcd45Oj+bJmqFORQ+9yemlVNkNjQpv2rwZsV1NgGAydesj3VT2nq91NgUCYiAQC4UAecDbwhHP8CeAc5/nZwPPGmHpjzC4gE5glIkOBaGPMMmOMAZ70u0apAe+tdXnkltXyp7MnkhIbxscb9tjuoVb2VdQxf0ISg0PdvPTOIjxe0+79vF7DA0t2sODeL4gODeSEsYPseIS4IH5kxxURgTP/Bec8AEGhLQ5NS4+lkBjqg+PabUnUNXp4aWU2lXWNbcqvfmIlb6/PI7+ijk+/LuS86Sk2mZ+7AZY/YMdA0o+CwOBO/LbU4XbIK66NMbki8g9gD1ALLDbGLBaRIcaYvc45e0VksHNJCrDc7xY5Tlmj87x1eRsicg22xUF6evqhVl2pPsPt8XLfx5mMTYrixHGD+Xx7IQtWfxfPM0m4rnyrxXmFlfWMGhzJ5d6vmL3zXn74z1ouOON0Tho/pMU97/pwO3d9uJ35E5L40zkTGBwVaoNEwsgDfxB3sJBt3NBoQgJd5IWMYHg7LYlHP9/F39/bxt0fbefOi6cyY5hdRb0qq5QPtuTz8bYC5h0xCK+B86en2sVzT54Ne5bCiBPgjH8e3C9OHTZd6W6Kw7YOhgPJQISIXLq/S9opM/spb1tozMPGmJnGmJmDBg062Cor1ee8sDKbHYXV/OSkIxARFkavY7p8jWv3p3aBmaO4ugGvgSExocyJLSdADN+ve4zvP/UVWcXNGVrf27SPuz7czgUzUnng0uk2QIDtbupgZlNnBLkCmJwawyZ3ChRssUkCHVX1bh75bCdT0mIxBi56aDlrs23ivmU7inEFCOOGRvHR1gJmDotjxKBIyFpqA8Qpf4HLXrMBTPVJXeluOgnYZYwpNMY0Aq8CRwP5ThcSzqOvgzUH8Nu8llRs91SO87x1uVIDWlW9m3+//zWzMuI5dcIQ8LgZs/FO8nD66ze+0nTuPmfQOik6FKnIAYQZnvXMk7W8vzkfgOySGn72wlqmpMXyl3MmNm8Dmv0VlOzc/3hEJ0xPj2NJZRo01kD+xqbyJ5ftpqymkT8umMA7Pz6WIJfwyirbObB0RxGTU2N48ntHcfK4wdx40mh70ZcPQ1gcHHm1Znrt47oSJPYAs0Uk3JmNdCKwBXgTuMI55wrgDef5m8BCEQkRkeHYAeovna6pShGZ7dzncr9rlBqwHvpkB0VVDfz6jHH2A33ds0jx17w19MdsDBgDG/yChDNoPSQ6BMpzYMxpED+CP4c+y5b1KwF4ekUWdW4v939nul0X0VgLr10Hj54EkYNh4gVdqu+09Fi+cDuBZvcXNLi9bN1XwX8+28W8IwYxNS2WGCp5JO4Z8jZ8TEVdI+tzypkzIoH4EMMj5ddy7La/Qlk2bHkLpl3WrckCVc/oypjEChF5GVgNuIE1wMNAJPCiiFyFDSQXOudvEpEXgc3O+T8yxvjarD8AHgfCgEXOH6UGLGMMjy/dzemTkpiaFgt15fDRbZAyE/fIM3hpz04m5j9h8y0NHts0sykpKgTKc+101SOvJunZS/hn4fepf/Yt3tqxkG+NHUJKbBh43PDyVbDtf3DMz+zmPV3c4W16ehx7SaAiLIWKte/zrXeG0+D24gqQ5hbCJ3/j2Iq3OJa3WP3YalzeBRw9MtGuqC7ZYf9se9cmCzzyqq7+GtVh0KXZTcaY3xtjxhpjJhpjLnNmLhUbY040xox2Hkv8zr/NGDPSGDPGGLPIr3ylc4+RxpjrnVlOSg1Y5bWNVNa5mZ7uLCP66C92odrpf2NCSgzveGZjJAA2vgzYloQrQEgIrIXGapvue9SJbL54KQ+7zyDk6zeZWruci2em2UHh//0ctr0Dp91hV053wxagg6NDSYkNY6l7LBH7vmRGWjR3XjyV9396nH0fxTvgq0dwT7qYx72nM73gVb4XtJgZw+Jg+wd2v+p5v4LKPLtvdVxGl+ukep6uuFaqF+Q66TdSYsMgd5XdsnPW9yFlBhOSYygihrzYmbZbBsivqGdwVAiuCmciYIydADhx9EgeCb6cQhPD+SFf2TQX29+HVY/DMT+Fo67t1npPS4/l/erRxEkV/zktgnOmpdiBaIAP/wiuEAJP+TNfjvkFq72juCTkC8KCAmy6j4y5cMKv4fI3bJpy1S9okFCqF+SV2e6j5NgweO9WiBwC3/oNAIOiQhgSHcK6wEl26mpdOfkVdQyODrXptMG2JABXgDBv3FAWeWZxnKwm0FMLKx6AqKFwwq3dXu/5E5PYGzcdgIi9K2zr4eXvwf1Hw+Y3YO4NEDWE0ycN5RXPcaS7s2ygK/q6eUX3iOMhakiHr6H6Fg0SSvUCXyK/5JgQyF0Nky6wWVAdE5Jj+KzaWQuUu5p95XUk+QatAWKaJwqeOy2Fj11zCfLWw9J7YMdHMPOqNtleu8OZk5N59pcX29ff9Bo8scB2JcWmwXE3wdwbAThp3BDCp12IcYXAOz+3F+tmQv2SBgmlekFeeS3BrgASTCl46tv0z09IjmZRmbOmNHcV+RV1JEWHQnk2uIIhvDmtxdxRiTz2ux/b1siS2+3xGVf27BsYNtfmXKqvhCvfhm+/AN+6tWm2UmiQi1svOBoZcxpUF0DsMJumXPU7GiSU6gV5ZXUMjQ0loNxZMNcmSMRQ5g2nLmYknuyVVNS5bXdTeQ5Ep7RJqS2uQLv/NAYmXQiRPbzYdOL5Nih95yUYOrnj86ZcYh9Hn6zrIfopDRJK9YK8slqSY8KgNMsWxA5rcXxCcrQ9L2IcJnclYJyWRG7TeEQbU78D4Qkw50c9WHPHEafAz7fZnEv7M+okOOoHMOuanq+T6hEaJJTqBXlltXbQuswXJFrmIkuNCyMmLIgNjCawppBkikmKcVoSHQWJ5Klw004YMqGHa+/oTMvAFQin3d6llCCqd2mQUOowa/R4ya+oIyU21LYkIpPaZF0VESYkR/NOcTIAUwMyGRIZaNcYdBQklOoBGiSUOszyK+rwGhjqa0nEDWv3vOvmjeTTyiTqTRBTA3aQFFBmVyprkFCHkQYJpQ6zFmskSrPajEf4HHfEIP56wXQ2mWEc6dpOZO1eeyBag4Q6fDRIKHWY1DbYVGV7y53V1lEuqMjZb3qK86anEjj2NKbJ17DYLrbTloQ6nDRIKHUYVNW7mfmX93lqeVZTSo5kKbHdRx10N/lMXvgnmH455Npsr76UHEodDoecBVYp1Xl7imuobvDw4JIdHDc6gdjwIMKrs+3BDrqbmgQEwJl32X2gc76EkKier7BSDg0SSh0GvjQc+8qq+PH675MRfi6UTbQHD9CSAGygOP1vPVhDpdqn3U1KHQZ5zjjExMgqkqWIS+ufh30bISDQrqBWqo/SIKHUYZBXVkeQS7h+WjAAEd5Km847JhUCXL1bOaX2Q4OEUodBXlktQ2PCOH5IDQAVMWPA23jg8QilepkGCaUOA5uGI5SgimyQAKIvuM8e6Mx4hFK9SAeulToM8spqmT0iwa6wjk6BtCNhwb2QMqO3q6bUfmmQUKqHuT1e8ivr7QrrHL8V1tMv692KKdUJ2t2kVA8rqKzH4zXNWV+1i0n1IxoklOphvjUSqVEClXt1sFr1KxoklOpheeU2oV+aq8QWaEtC9SMaJJTqYb6WxBDPPlugLQnVj2iQUKqH5ZXVEh0aSHh1ji1otQudUn2ZBgmlelheWV3zoLUrGKKG9naVlOo0DRJK9bCm/axLsyAmzSbrU6qf0H+tSvWwvHK72lqnv6r+SIOEUj2opsFNWU3jAbcqVaqv0iChVA9asdNOez0irApqS7QlofodDRJK9RCv1/C397aRFh/GCXvuBlcIjD+7t6ul1EHRIKFUD3lzXR5b9lZw+7RSXJtegWN+CvEjertaSh0UDRJK9YB6t4d/LN7G5KQwjt52O8RlwDE/6e1qKXXQNEgo1QOeXbGHnNJa7hr2BVL0NZz2dwgK6+1qKXXQuhQkRCRWRF4Wka0iskVE5ohIvIi8LyLbncc4v/NvEZFMEdkmIqf6lc8QkQ3OsbtFRLpSL6V6U2VdI/d8lMlZwzxkbL4fxp4JR5zS29VS6pB0tSVxF/CuMWYsMAXYAtwMfGiMGQ186PyMiIwHFgITgPnA/SLi29z3AeAaYLTzZ34X66VUr3nk052UVDfw59CnEWNg/v/1dpWUOmSHHCREJBo4DngUwBjTYIwpA84GnnBOewI4x3l+NvC8MabeGLMLyARmichQINoYs8wYY4An/a5Rql8pqKzjkc92cdOILGKz3oN5v9RcTapf60pLYgRQCPxXRNaIyH9EJAIYYozZC+A8DnbOTwGy/a7PccpSnOety9sQkWtEZKWIrCwsLOxC1ZXqGfd8mEmAp47vVz0ICaNhzo97u0pKdUlXgkQgMB14wBgzDajG6VrqQHvjDGY/5W0LjXnYGDPTGDNz0KBBB1tfpbqPMdBY26JoV1E1z325h3vSlhBUkQVn/AMCg3upgkp1j64EiRwgxxizwvn5ZWzQyHe6kHAeC/zOT/O7PhXIc8pT2ylXqs+pa/SQm5sDT58Hf02GZxdC5gfg9fKPxduY59rACUXPwsTzYcTxvV1dpbrskIOEMWYfkC0iY5yiE4HNwJvAFU7ZFcAbzvM3gYUiEiIiw7ED1F86XVKVIjLbmdV0ud81SvUZBZV1/OTe5zEPz6Nxx2cUjb4QclfC0+dT/a+pnLXlJh51/RWJGwan/rW3q6tUtwjs4vU/Bp4RkWBgJ/BdbOB5UUSuAvYAFwIYYzaJyIvYQOIGfmSM8Tj3+QHwOBAGLHL+KNVnZBVXc+mjK7i9+kHigtxc6fkTX6wfxjHDv8MZ8SsZnfU8J7rWUD/np4R862YICu3tKivVLcROKOp/Zs6caVauXNnb1VDfEFf+90sqstbxKr+AE39H9awbee7LPTzy2U7yK+q58ugMbjntCEKCgnq7qkrtl4isMsbM7Oz5XW1JKDXg7S2v5dOvC3k97TMoCYMZ3yUiJJCrjx3BZXOGUVzVYFOBKzUAaVoONXA11sJX/4Gqrk2XfnV1LrGmgknF78KUhRAe33QsJNClAUINaBok1MD1v1/AOz+Hh46FrKWHdAtjDC+tzOZPCYsRTz0cdV03V1Kpvk2DhBpwdhZW8cS9f4I1T8O0S21ivcfPhF2fHfS9vtpdypllz3Bm9asw7TIYPLYHaqxU36VBQg0oHq/hmaf+w8LCu/nCTObjI34D13xiu4hWPNj5G3m9eHd+RuPL1/CLoJdwT7wIzrqr5yquVB+lA9fq8DIGti2C4cdCSFTX71WRCzs+hqKvIXE0a9at59by/1ASdQT3uH7FV0+t4bUfHs3kyRfbIFFVAJGD93/funJ45kICslcwzYSwMf07TDzvHghw7f86pQYgDRKqZ617Hhb/Fo79ORx1Lbz3a1h+P8y6Fk7/28Hfb+86+OxfsHMJ1FeCb6mNuMB4mAksjzqJo254koc8wcy67QNeWZXD5KMvh2X32vrMvaHlPUt2wcaXITAMhh+H+82fIPvW8tvGqwifcQm3njsTNHu9+obSIKF6htcLH/welt4NEYPg3V9h1j2H7F0L4Qmw7jk48bedZqHopQAAFQxJREFUa03kroKvHoO81VCwGUKiYcI51IfEUypxxE88kVXVQ/jT04tIDqnj9muuQIJDiQGOHzOIRRv38fuzTiQgdRaseQqGToH3fwe1peAKguJMbAoxu2bIGBc/aLyR0EkL+PM5U9HtTdQ3mQYJ1SNqF/+RsOV3Uz/te4SccTs5b/yJ1A33kjfyYpKPvxoePRnWvwBHXt3yQo8bVjwA0Skw8TyoLoZnLgJPIxWDprFh+MksjzuL9UWGpTuKaPQYgj/JwZBNRkIGf7lqFoOim1c7nz5pKO9tymdlVimzpl8Gb/4YnlxgtxNNn4O3oQYmX0LA1Et4/PPtZC59ncGjZvKL085mTFIXu8OUGgA0SKhuV7bqVWKX38mz7hN4bs/53Lavlis2zSO4biwT3WN4NPVI+23+y0dg5lV2DKC+Ahpq4J2fQdYXIAHgCsa76XWktoy/pj/EI9vseoTQoCKSY8K48ugMJiTHsGVvBdUNbn5+8hjiIlpmXT1x3BCCAwP434a9zDr1PGq+fIrywTPZO+UGXt9YzEubcoj7//buPD6q8t7j+Oc3M5mZrGQjISEBgmHfBBFEUDYViyxWW7uopXW7tda1VuF6tdd721uXVu0G1pe27liqKC51RQWLAgICgqwBIYGQAAkkIfvMc/94DhAwA4EEZgZ+79crr8x55szMN5M55zfPc7bNMZyzYyezv9jHZQN/zM1XDNDeg1IOLRKqbVSWwOdPUlNWhHfVbFaafMpH/oZ187Yy6c8LSPJ7GNyvD++u3kFZdQOpQ26AOTfB4yOgZDUHzg4fEwcT/wjLniUwawpu08gfGi/j+U0J3DK2K9efl0ei/9BTX1w6sNnLjwCQ4PMwsnt73l5VTCBoeO7r2+BrYPEyvG4XE/pnsaemgTkrtjM0L5XfXt5PC4RSTWiRUMenoQZqKyAx0/5+7tuYnWuodSWzweTh/95T3NS7D2fmZXL/G6u5b0If0hK8vPVlMW+t3M7Vgy+Hz6aDxwcj76YuPps3lhfhzR/JpLNGsDF1JK6/X4zHF0vXiffx7x7ZpCX4jivqJf2yeP+rEp5buIXrRuRxfvf21DQEGJibTIYzNFVR24Df48br0b3ClWpKi4Q6NsbAV3PsXkoV2+1pKqpKYOda5g+ZwZR5ifxqYm9+0jsPgOH56bx3+8gDD+/ZIZFXv9jG1cO6YG5cAMDOqjquefpzVm1Lx7V5L5lddjNjXimrXA/z/k3nMTE5uVWRL+qTyeWDcpjQP4vRPZvf/TXJryfmU6o5WiTUsfn0j3bPoMx+0GsiZsnfkUAdn/W5j58vTGFIXhJThnUJ+fDJZ3bkwXfWcvPML/h4XSmVtY0AxMa4+dMPBvLo++u57tklVNY28p/je5PSygIBEOf18PsrBrT6eZQ6HWmRUMdm41xbIG74GONyc2/JKLasX84nS3uSnuDmd98ZgMsVekx/8pnZPPr+ej5eV8pFvTvQMSUWjOFb/bLolZVEfkYCl/5lAR2TY/nREYqNUurk0CKhWiwQNNRsX8Pa2IF0qm7kwzXbeX5tkFvGXMbDQzuTnuDF4z7ymH52cizz7xpNSnwMPs83j2DulZXEP386jASfB3+MHuGsVLhpkVAtUlJRy90vLuDpulI+3JfCC4/Mp74xyPD8NG67oPsRew+H69DuyFdt65/T+iEmpVTb0F05VIv8+q01VG1bA8DVEy4kPyOBBL+HR64485gKhFIqumhPQrXIxtIqLs+sgF2QdUZ/Xh7azR7trLuMKnVK0yVcHZUxhqKyarq7i8HlgdQ8REQLhFKnAV3K1VHtrWmgsq6R3GARpOTZk+IppU4LWiTUURWW1QCQXrcV2vcIcxql1MmkRUIdVVF5NW4CxFdtgfRu4Y6jlDqJtEiooyosr6aTlOIKNkB693DHUUqdRFok1FEVltXQz1diJ7RIKHVa0SKhjqqwvJozY0vtRFp+eMMopU6q0/M4iX274M3bYPR/QUbPcKeJLLV7YU+hvQgQQEwcPUv+xbjgPEjIhFg9Glqp08npVySCQZh9AxTMhcRsGP9QuBO1Xu1ee73mlC7H/thgABAwQVj8BHz0f1BfecgsU4HKmHQYcWdbpFVKRZHTr0gseMwWiPgMWPM6XPwAuCJ41C0YgAV/gF3rIXcoZPaFuFRbFDbOtX9L0RIwAci/AM6+3h7H0FBtLwcabID49tAuFzJ6QdOrrm2eDy9fA9Vl9opw9ZX2OQZeDf4kQNizt5wp/yzksgsnMuWcrmF7G5RS4XHqFondBbDsGdjyqV25Zg2AtW/ZwtDn29BjPMy+HooWQ6dzTnyehlpY9xb420FaN0judOgKuzk15fDytbYQ+JNhxczDZhDIHggjbgePHxbNgJnfC/18nUfAhf8DvkTY+L69LkRaPgyaYl/rjNHQc8IhuQq2lLPCfMqtafHH/7crpaLWqVUkNn0M/7oLKovtmLq4bXFY/AQE6iEuDYb+FEZNs/O7vfYqa21RJIJB2LnWvk4wAHV7obHOjuPXlNlcZQUH5+94ls3ib2fzevw2n7igsRYKPoRVr0BdFUx4DM76MZRtgt0bnW/+fuhyPsSnHXzOYT+zvQqPz/YMvPHgckPVTti2BOY/DE+OOTh//gXwnb/ZDCEUlVcDkJMS1/r3SCkVdU6dIhFogDdvh0AjnPlD+029z2WQlGVXtDvXQYd+4PEefMwZY22RGHI9/Psxu2LNGWxXrJU77Dy+JDtkU73brpyryyAmFjqfC11HQXy6LRCvXAOrXw2dL7kz/OAf9lt88XL4/CnbkwnF47ff6of9zBYUgLQz7E8o3njoOvKb7SldIPds+76snGUzpOVD9qCjDrUVldujrXNSYo84n1Lq1HTqFInlL9pv2j94CXp869D7fAmQY1e0waA5eGrr3pNh/dvwp8H227cxdsgmlJg4+22/Zg8secpOj7kX9hbZAjHidsg5254Ez5dkC1LlDlukek0Er/NtvMtwGHojFC6y8yZ2sD2Q6t02gzvGrsT9SW37Hvnb2YJ4DArLqklP8BLnPXU+Kkqpljs1lvyGWpj3IHQcDN0vDjnbsq3lXPXkIl64bigDO6XYYpLa1a7YL7jf9gp2rrVDPgkd7Nh8XYVdkcemHlzJBxphxwr4+AF41xm6GvIfMPZXR9/OsJ/LBZ2HHdp2pF7CCbZ51z42lFSyp6YBtwjxPjcLN5Xx5spiemUlhi2XUiq8Wl0kRMQNLAG2GWMmiEgq8A+gC/A1cIUxptyZdxpwLRAAbjHGvOu0nwU8DcQC/wJuNcaYI75w/T67UXf7Mjv2X7ENLp0eciUdDBp+NWc11fUB3v+qxBaJ2GS45YtDZ+zQ79DpuNRvPpnbY4eAfjgLVs+2Q1kj7255gWgjwaB9i1pz0R9jDE/9ezO/fXstgeChb7nX7WJc3w7cOlYPoFPqdNUWPYlbgTXA/rGRqcBcY8wDIjLVmb5bRHoD3wf6ANnAByLS3RgTAGYANwALsUXiYuDtI77qrvWwYZ/dI8cdY08X0XVUyNn/ubSQL7ftJd7r5tOC3cf/1zYlAn0vb5vnasbCTbvZU93Aed3SiffZf5UxhrU7KpmzfDtvrNhORW0DvxzXgyuHdsbtFAtjDEHDgenDFe+t4RezVlBdHwBgeeEexvXJ5Oeju5EcF0PQGCprG+mYHEtKvLfZ51BKnR5aVSREJAe4BPgNcIfTPBkY5dx+BvgYuNtpf8kYUwdsFpGNwBAR+RpIMsZ85jzns8ClHK1IJOfCL1bbjbWHqaxtYN2OSgbkJhPjdrFpZxUPvbOOwZ1TGNo1lcfnbaKytoFEf+ReF+GdVcXc9OIXBIIGr9tFz6xEMhJ9bC2rZn1JFW6XcH63dOoag9w3ZzUzPi7AJcK++kaqahsJGEOHJD/5GQnceVEPBuTaI6XL9tVz1ZOLKKmoY2CnZHZX1XPP+F5cd569kJBSSjXV2p7EY8BdQNNB60xjTDGAMaZYRDKc9o7YnsJ+RU5bg3P78PZvEJEbsD0OOnXqdEiB2FfXyLY9NcxdU8pf5xewp7qB9AQvfbLb8cmGnfg8bv57Uh8qahr4y0cFfP51GWN6Zrbqj2+J5YV7mP7RRjKT/PTtmMSE/tkHegWhvLt6BzfP/IL+Oe2448LuzFu3k/WlVWzbU0tynJf/vbQv4/t2IC3BhzGGN1YW886qYvwxbhJ9HuJ9HjwuoWhPDQs27uLyGZ9y0+h8EnweXllWRFF5Dc9eM4ShXdOOmEMppY67SIjIBKDUGLNUREa15CHNtJkjtH+z0ZgngCcABg8efGCe5xZu4d7XVh2Yb3SP9kzon817X+1geeEebjj/DK4dkUf7RB+1DQG8bhefFexukyIRDBrWl1bSGDDUNQYo39dAXWOQzmlxrNtRybRXvyTe66YhYHhu4RZ+/956br+wO0n+GIrKq4nzechM9OF2CRW1Dfzj80IWbiqjb8cknv7JENrFxnBet/YhX19EmDQgm0kDspu9f291A1Nnr+QPczcAkN3Oz+NXnaUFQinVIq3pSQwHJonIeMAPJInI80CJiGQ5vYgswDl9KEVAbpPH5wDbnfacZtpbpDEQ5C8fbmRAbjLXjsije2YCPTvYzSOXn5Xzjfn9MW4GdU7m04LdVNc38vzCLaTF+zi/e3tE7C6fbpeQEueltiFASUUdJRW1lFbWkRIXw9hembRP9B14vjtmLee15aHjDslLZcaVg0iJ87J0azm/fmsN02Z/GXL+zCQf/3VJL344tFOb7HbaLi6G6VcOYkNpFekJPlJ1G4NS6hgc91rIGDMNmAbg9CTuNMZcJSIPA1OAB5zfc5yHvA68KCKPYDdcdwMWG2MCIlIpIucAi4AfAX9qaY6P1u1kR0Ut90/uw7g+HVr0mGFd03ls7nom/3kBG0qrWvpSAIh8yUW9M3n4uwP4ZP0uXlu+nSnDOjM8P50Yj4vUOC8xbhdby/axry7AxAHZeD32gLWzu6Ty6o3nsnRrOfFeD7mpsVTXByipqAXA53GTlx5/YP62IiJ0z9TdWJVSx+5EHCfxADBLRK4FtgLfBTDGrBaRWcBXQCNwk7NnE8CNHNwF9m2OttG6iZmLt5KR6GNMz4yjz+w4Nz+NRz+A3fvqeeaaIaTGeVlQsAu/x0VOShwGKK+uxx/jJjPRR0aS/8BG4zdXbuev8zZx2fRP2V1VR/+cdtw7oTce96Er9t7ZzR8I53IJZ3c5uFttoj+GzCR/i7MrpdTJJEc7HCFSDR482Mz54BPOe/BDfjYqnzvH9WjxY40xvLJsG8Pz08hqd+ynm/isYDc3vrCU6voAb908gm76LV0pFSVEZKkxZnCL54/WIpGU28P0vnE6JZW1zP/laHJTT+4J6Ir31rC7qp6+HUOfHE8ppSLNsRaJqD0tx/4N0P1zkk96gQDIahd7XL0QpZSKJlFbJDqlxjH9yrPCHUMppU5pEXxJNqWUUuGmRUIppVRIWiSUUkqFpEVCKaVUSFoklFJKhaRFQimlVEhaJJRSSoWkRUIppVRIUXtaDhGpBNaFO8dRpAO7wh2iBaIhp2ZsO9GQUzO2ncNzdjbGhL5IzWGi9ohrYN2xnH8kHERkSaRnhOjIqRnbTjTk1Ixtp7U5dbhJKaVUSFoklFJKhRTNReKJcAdogWjICNGRUzO2nWjIqRnbTqtyRu2Ga6WUUideNPcklFJKnWBaJJRSSoUUlUVCRC4WkXUislFEpoY7D4CI5IrIRyKyRkRWi8itTnuqiLwvIhuc3ykRkNUtIl+IyJuRmFFEkkXkZRFZ67yfwyIto5Pzdud/vUpEZoqIP9w5ReRvIlIqIquatIXMJCLTnOVonYiMC3POh53/+UoReVVEksOZs7mMTe67U0SMiKRHYkYRudnJsVpEHmpVRmNMVP0AbqAA6Ap4gRVA7wjIlQUMcm4nAuuB3sBDwFSnfSrwYARkvQN4EXjTmY6ojMAzwHXObS+QHIEZOwKbgVhnehbw43DnBM4HBgGrmrQ1m8n5fK4AfECes1y5w5jzIsDj3H4w3Dmby+i05wLvAluA9EjLCIwGPgB8znRGazJGY09iCLDRGLPJGFMPvARMDnMmjDHFxphlzu1KYA12RTIZu9LD+X1peBJaIpIDXAI82aQ5YjKKSBL2g/8UgDGm3hizhwjK2IQHiBURDxAHbCfMOY0x84Gyw5pDZZoMvGSMqTPGbAY2YpevsOQ0xrxnjGl0JhcCOeHMGeK9BHgUuAtoutdPJGW8EXjAGFPnzFPamozRWCQ6AoVNpouctoghIl2AgcAiINMYUwy2kAAZ4UsGwGPYD3iwSVskZewK7AT+7gyJPSki8RGWEWPMNuB3wFagGNhrjHmPCMvpCJUpkpela4C3ndsRk1NEJgHbjDErDrsrYjIC3YHzRGSRiMwTkbOd9uPKGI1FQpppi5j9eEUkAXgFuM0YUxHuPE2JyASg1BizNNxZjsCD7T7PMMYMBPZhh0giijOuPxnbbc8G4kXkqvCmOmYRuSyJyD1AI/DC/qZmZjvpOUUkDrgHuK+5u5tpC9d76QFSgHOAXwKzREQ4zozRWCSKsGOC++Vgu/lhJyIx2ALxgjFmttNcIiJZzv1ZQGmox58Ew4FJIvI1dphujIg8T2RlLAKKjDGLnOmXsUUjkjICXABsNsbsNMY0ALOBc4m8nBA6U8QtSyIyBZgAXGmcgXQiJ+cZ2C8FK5xlKAdYJiIdiJyMOFlmG2sxdtQgnePMGI1F4nOgm4jkiYgX+D7wepgz4VTqp4A1xphHmtz1OjDFuT0FmHOys+1njJlmjMkxxnTBvm8fGmOuIrIy7gAKRaSH0zQW+IoIyujYCpwjInHO/34sdjtUpOWE0JleB74vIj4RyQO6AYvDkA+wey0CdwOTjDHVTe6KiJzGmC+NMRnGmC7OMlSE3VllR6RkdLwGjAEQke7YnT92HXfGE731/QRt0R+P3XuoALgn3HmcTCOwXbeVwHLnZzyQBswFNji/U8Od1ck7ioN7N0VURuBMYInzXr6G7TpHVEYn5/3AWmAV8Bx2r5Gw5gRmYreRNGBXYtceKRN2+KQAe9r9b4U550bsmPn+5efxcOZsLuNh93+Ns3dTJGXEFoXnnc/lMmBMazLqaTmUUkqFFI3DTUoppU4SLRJKKaVC0iKhlFIqJC0SSimlQtIioZRSKiQtEkoppULSIqGUUiqk/wdSPjVXOL8qYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "# YOUR CODE HERE!\n",
    "btc_closing.plot(title='BTC predictions using closing price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
